{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90435ffd018449798d7bdcb77e9831a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f31c623f6be24746bfd919cb5602d233",
              "IPY_MODEL_d0cfa06a007f489faf2311148d7630c6",
              "IPY_MODEL_916c0193a6b14306bc14e5809a0f967c"
            ],
            "layout": "IPY_MODEL_8fb997661795465a94b7790a6ba07ae9"
          }
        },
        "f31c623f6be24746bfd919cb5602d233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c4bb65bb5ba4e678f10fe0b80d6c0ae",
            "placeholder": "​",
            "style": "IPY_MODEL_5317ff4f5ec842fbb315750f49787ede",
            "value": "Map: 100%"
          }
        },
        "d0cfa06a007f489faf2311148d7630c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_727db1faca984d8f8849f7c5ae7eeff9",
            "max": 7763,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b35c6bb498542fab5fb6ee0069cfc3b",
            "value": 7763
          }
        },
        "916c0193a6b14306bc14e5809a0f967c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31e342c30dfc4253a95c742b7170e186",
            "placeholder": "​",
            "style": "IPY_MODEL_66266efe71b54d6ab50ee20fca716ddc",
            "value": " 7763/7763 [00:00&lt;00:00, 17495.63 examples/s]"
          }
        },
        "8fb997661795465a94b7790a6ba07ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4bb65bb5ba4e678f10fe0b80d6c0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5317ff4f5ec842fbb315750f49787ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "727db1faca984d8f8849f7c5ae7eeff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b35c6bb498542fab5fb6ee0069cfc3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31e342c30dfc4253a95c742b7170e186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66266efe71b54d6ab50ee20fca716ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d20a77261d84f7ba730085e68b9f5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a9843240adf432cb9bd9b8c0dfe032e",
              "IPY_MODEL_2e59ca259a4447a5bf41280503f22f4a",
              "IPY_MODEL_980eb06d64f5456697a11c359269c044"
            ],
            "layout": "IPY_MODEL_496e945dd7a24b1e9843c07294ea3ae4"
          }
        },
        "9a9843240adf432cb9bd9b8c0dfe032e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40a5800165674e738bfac918410cb3b7",
            "placeholder": "​",
            "style": "IPY_MODEL_172b70a8c3794b77b51011456fd6350e",
            "value": "Map: 100%"
          }
        },
        "2e59ca259a4447a5bf41280503f22f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b71188233fc341af9c39782aa3b8a732",
            "max": 409,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8c05151323f42a6ac8adae91a0754bf",
            "value": 409
          }
        },
        "980eb06d64f5456697a11c359269c044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c8f95d658e14d4694181a020f4c4b2d",
            "placeholder": "​",
            "style": "IPY_MODEL_9b13ac9807c14ff8997fc8f23c302753",
            "value": " 409/409 [00:00&lt;00:00, 10978.31 examples/s]"
          }
        },
        "496e945dd7a24b1e9843c07294ea3ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40a5800165674e738bfac918410cb3b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172b70a8c3794b77b51011456fd6350e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b71188233fc341af9c39782aa3b8a732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c05151323f42a6ac8adae91a0754bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c8f95d658e14d4694181a020f4c4b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b13ac9807c14ff8997fc8f23c302753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98e7f0aef7a343feb360832f8583b69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_003a8b6fcb424f3ab260bb8466aef801",
              "IPY_MODEL_c1e663d874dc4f1a83b5419244b74ba4",
              "IPY_MODEL_25157aa3f34a43ca8b4098b6311619b1"
            ],
            "layout": "IPY_MODEL_ce8c9f7c49f8474092c469e38d4a9a74"
          }
        },
        "003a8b6fcb424f3ab260bb8466aef801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb1f4a2751de4a888baaabb0623fe2d6",
            "placeholder": "​",
            "style": "IPY_MODEL_7da73e9ca87d47679e3fc4a467671f26",
            "value": "Map: 100%"
          }
        },
        "c1e663d874dc4f1a83b5419244b74ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c20f59577734c309997162c96e58e1c",
            "max": 7763,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cf2bf21baeb4c9ca85c7b252c6e03ec",
            "value": 7763
          }
        },
        "25157aa3f34a43ca8b4098b6311619b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c016193de88a4fdfad1b97f462584056",
            "placeholder": "​",
            "style": "IPY_MODEL_d74fe787e62d4065b4d69327fde030d5",
            "value": " 7763/7763 [00:14&lt;00:00, 553.56 examples/s]"
          }
        },
        "ce8c9f7c49f8474092c469e38d4a9a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb1f4a2751de4a888baaabb0623fe2d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da73e9ca87d47679e3fc4a467671f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c20f59577734c309997162c96e58e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf2bf21baeb4c9ca85c7b252c6e03ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c016193de88a4fdfad1b97f462584056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74fe787e62d4065b4d69327fde030d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ab939bec7d74c9ca7ecf00f93db8b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14f7ca47dcc1478689c4a80cd6b0ad76",
              "IPY_MODEL_0acd9bfa52494e4c92fc037d3f4effe1",
              "IPY_MODEL_e88225081f8042f1aafc5d09606df089"
            ],
            "layout": "IPY_MODEL_4958d4aa49d046278c50c90592d80375"
          }
        },
        "14f7ca47dcc1478689c4a80cd6b0ad76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_197a6789b3c34ec59ca1192f84ce4b79",
            "placeholder": "​",
            "style": "IPY_MODEL_298ea1dea85643daaceeb35d839f3a97",
            "value": "Map: 100%"
          }
        },
        "0acd9bfa52494e4c92fc037d3f4effe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30ac0970f29446bfbf0eaa9ace6d8db0",
            "max": 409,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfa18cda1574470ea3e190d5b05f9ffc",
            "value": 409
          }
        },
        "e88225081f8042f1aafc5d09606df089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50bb5ab875ef478892cc9565b0054ca3",
            "placeholder": "​",
            "style": "IPY_MODEL_8d6f954ce14246818a5d9c582072af32",
            "value": " 409/409 [00:00&lt;00:00, 584.28 examples/s]"
          }
        },
        "4958d4aa49d046278c50c90592d80375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "197a6789b3c34ec59ca1192f84ce4b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298ea1dea85643daaceeb35d839f3a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30ac0970f29446bfbf0eaa9ace6d8db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa18cda1574470ea3e190d5b05f9ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50bb5ab875ef478892cc9565b0054ca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d6f954ce14246818a5d9c582072af32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TaPjpRhnEzav",
        "outputId": "435ff4ee-fb36-4c99-8446-4378629a834a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Collecting trl\n",
            "  Downloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.41.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.25.2)\n",
            "Collecting accelerate (from trl)\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from trl)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tyro>=0.5.11 (from trl)\n",
            "  Downloading tyro-0.8.5-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.23.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (4.66.4)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets->trl)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->trl)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.0.3)\n",
            "Collecting requests (from transformers>=4.31.0->trl)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->trl)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->trl)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
            "Installing collected packages: xxhash, shtab, requests, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, nvidia-cusolver-cu12, datasets, accelerate, trl\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.32.1 datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pyarrow-16.1.0 requests-2.32.3 shtab-1.7.1 trl-0.9.6 tyro-0.8.5 xxhash-3.4.1\n",
            "Collecting peft\n",
            "  Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.4)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: peft\n",
            "Successfully installed peft-0.11.1\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.9.0-py2.py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.9.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.4\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install trl\n",
        "!pip install peft\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Optional\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, TrainingArguments\n",
        "\n",
        "from trl import DPOTrainer, DPOConfig"
      ],
      "metadata": {
        "id": "ejffFMBRRDui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A-FQ8BRUAw3",
        "outputId": "d09855bb-1881-41d4-a87c-5557a335c945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adapted from https://github.com/huggingface/trl/blob/main/examples/dpo.py\n",
        "\n",
        "def extract_codon_prompt(prompt_and_response):\n",
        "    \"\"\"Extract the start codon prompt from a prompt and response pair.\"\"\"\n",
        "    # search_term = \"ATG\"\n",
        "    search_length = 15\n",
        "    search_term = prompt_and_response[:search_length]\n",
        "    search_term_idx = prompt_and_response.find(search_term)\n",
        "    assert search_term_idx != -1, f\"Prompt and response does not contain '{search_term}' in {prompt_and_response}\"\n",
        "    return prompt_and_response[: search_term_idx + len(search_term)]\n",
        "\n",
        "from typing import Dict, Optional\n",
        "\n",
        "def split_codon_prompt_and_responses(sample) -> Dict[str, str]:\n",
        "    prompt = extract_codon_prompt(sample[\"chosen\"])\n",
        "    return {\n",
        "        \"prompt\": prompt,\n",
        "        \"chosen\": sample[\"chosen\"][len(prompt) :],\n",
        "        \"rejected\": sample[\"rejected\"][len(prompt) :],\n",
        "    }"
      ],
      "metadata": {
        "id": "1ka9sjuWRW3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adapted from https://github.com/huggingface/trl/blob/ca0af3944d4ce53f0db8d48fdd7c4459c41fd437/trl/trainer/utils.py\n",
        "# removed addition of EOS token id, causes an error\n",
        "\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "from collections import deque\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import IterableDataset\n",
        "from transformers import DataCollatorForLanguageModeling, PreTrainedModel, PreTrainedTokenizerBase, TrainerCallback\n",
        "\n",
        "@dataclass\n",
        "class DPODataCollatorWithPadding:\n",
        "    r\"\"\"\n",
        "    DPO DataCollator class that pads the inputs to the maximum length of the batch.\n",
        "    Args:\n",
        "        tokenizer (`PreTrainedTokenizerBase`):\n",
        "            The tokenizer used for encoding the data.\n",
        "        model (Optional[`PreTrainedModel`]):\n",
        "            The model that is being trained. If set and has the *prepare_decoder_input_ids_from_labels*, use it to\n",
        "            prepare the *decoder_input_ids*.\n",
        "        padding (`Union[bool, str, `PaddingStrategy`]`, `optional`, defaults to `True`):\n",
        "            padding_strategy to pass to the tokenizer.\n",
        "        max_length (`Optional[int]`, `optional`, defaults to `None`):\n",
        "            The maximum length of the sequence to be processed.\n",
        "        max_prompt_length (`Optional[int]`, `optional`, defaults to `None`):\n",
        "            The maximum length of the prompt to be processed.\n",
        "        label_pad_token_id (`int`, defaults to -100):\n",
        "            The label used for masking.\n",
        "        padding_value (`int`, defaults to 0):\n",
        "            The value used for padding.\n",
        "        is_encoder_decoder (`Optional[bool]`, `optional`, defaults to `None`):\n",
        "            Whether or not you model has an encoder_decoder architecture.\n",
        "        max_target_length (`Optional[int]`, `optional`, defaults to `None`):\n",
        "            The maximum length of the target to be processed. Only useful for encoder-decoder architectures.\n",
        "        truncation_mode: (`str`, defaults to \"keep_end\"):\n",
        "            The truncation mode to use when truncating the prompt.\n",
        "    \"\"\"\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    model: Optional[PreTrainedModel] = None\n",
        "    padding: Union[bool, str] = True\n",
        "    max_length: Optional[int] = None\n",
        "    max_prompt_length: Optional[int] = None\n",
        "    label_pad_token_id: int = -100\n",
        "    padding_value: int = 0\n",
        "    truncation_mode: str = \"keep_end\"\n",
        "    is_encoder_decoder: Optional[bool] = False\n",
        "    max_target_length: Optional[int] = None\n",
        "\n",
        "    def tokenize_batch_element(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        chosen: str,\n",
        "        rejected: str,\n",
        "    ) -> Dict:\n",
        "        \"\"\"Tokenize a single batch element.\n",
        "\n",
        "        At this stage, we don't convert to PyTorch tensors yet; we just handle the truncation\n",
        "            in case the prompt + chosen or prompt + rejected responses is/are too long. First\n",
        "            we truncate the prompt; if we're still too long, we truncate the chosen/rejected.\n",
        "\n",
        "        We also create the labels for the chosen/rejected responses, which are of length equal to\n",
        "            the sum of the length of the prompt and the chosen/rejected response, with\n",
        "            label_pad_token_id  for the prompt tokens.\n",
        "        \"\"\"\n",
        "        batch = {}\n",
        "\n",
        "        if not self.is_encoder_decoder:\n",
        "            chosen_tokens = self.tokenizer(chosen, add_special_tokens=False)\n",
        "            rejected_tokens = self.tokenizer(rejected, add_special_tokens=False)\n",
        "            prompt_tokens = self.tokenizer(prompt, add_special_tokens=False)\n",
        "\n",
        "            eos_token_id = self.tokenizer.eos_token_id\n",
        "            # print(f\"eos_token_id: {eos_token_id}\")\n",
        "            # Get indices in list prompt_tokens[\"input_ids\"] that equals the EOS token (often 0)\n",
        "            eos_indices_prompt = [i for i, x in enumerate(prompt_tokens[\"input_ids\"]) if x == eos_token_id]\n",
        "            # attention mask these indices to eos_token_id\n",
        "            new_attention_mask = [\n",
        "                0 if i in eos_indices_prompt else p for i, p in enumerate(prompt_tokens[\"attention_mask\"])\n",
        "            ]\n",
        "            prompt_tokens[\"attention_mask\"] = new_attention_mask\n",
        "\n",
        "            # do the same for chosen and rejected\n",
        "            eos_indices_chosen = [i for i, x in enumerate(chosen_tokens[\"input_ids\"]) if x == eos_token_id]\n",
        "            new_attention_mask_c = [\n",
        "                0 if i in eos_indices_chosen else p for i, p in enumerate(chosen_tokens[\"attention_mask\"])\n",
        "            ]\n",
        "            chosen_tokens[\"attention_mask\"] = new_attention_mask_c\n",
        "\n",
        "            eos_indices_rejected = [i for i, x in enumerate(rejected_tokens[\"input_ids\"]) if x == eos_token_id]\n",
        "            new_attention_mask_r = [\n",
        "                0 if i in eos_indices_rejected else p for i, p in enumerate(rejected_tokens[\"attention_mask\"])\n",
        "            ]\n",
        "            rejected_tokens[\"attention_mask\"] = new_attention_mask_r\n",
        "\n",
        "            # # add EOS token to end of prompt\n",
        "            # chosen_tokens[\"input_ids\"].append(self.tokenizer.eos_token_id)\n",
        "            # chosen_tokens[\"attention_mask\"].append(1)\n",
        "\n",
        "            # rejected_tokens[\"input_ids\"].append(self.tokenizer.eos_token_id)\n",
        "            # rejected_tokens[\"attention_mask\"].append(1)\n",
        "\n",
        "            longer_response_length = max(len(chosen_tokens[\"input_ids\"]), len(rejected_tokens[\"input_ids\"]))\n",
        "            # print(f\"longer_response_length: {longer_response_length}\")\n",
        "\n",
        "            # if combined sequence is too long, truncate the prompt\n",
        "            # print(f'prompt_tokens_input_ids: {prompt_tokens[\"input_ids\"]}')\n",
        "            # print(f'chosen_tokens_input_ids: {chosen_tokens[\"input_ids\"]}')\n",
        "            if len(prompt_tokens[\"input_ids\"]) + longer_response_length > self.max_length:\n",
        "                if self.truncation_mode == \"keep_start\":\n",
        "                    prompt_tokens = {k: v[: self.max_prompt_length] for k, v in prompt_tokens.items()}\n",
        "                elif self.truncation_mode == \"keep_end\":\n",
        "                    prompt_tokens = {k: v[-self.max_prompt_length :] for k, v in prompt_tokens.items()}\n",
        "                else:\n",
        "                    raise ValueError(f\"Unknown truncation mode: {self.truncation_mode}\")\n",
        "\n",
        "            # if that's still too long, truncate the response\n",
        "            if len(prompt_tokens[\"input_ids\"]) + longer_response_length > self.max_length:\n",
        "                chosen_tokens = {k: v[: self.max_length - self.max_prompt_length] for k, v in chosen_tokens.items()}\n",
        "                rejected_tokens = {\n",
        "                    k: v[: self.max_length - self.max_prompt_length] for k, v in rejected_tokens.items()\n",
        "                }\n",
        "\n",
        "            # Create labels\n",
        "            chosen_sequence_tokens = {k: prompt_tokens[k] + chosen_tokens[k] for k in chosen_tokens}\n",
        "            rejected_sequence_tokens = {k: prompt_tokens[k] + rejected_tokens[k] for k in rejected_tokens}\n",
        "            chosen_sequence_tokens[\"labels\"] = chosen_sequence_tokens[\"input_ids\"][:]\n",
        "            chosen_sequence_tokens[\"labels\"][: len(prompt_tokens[\"input_ids\"])] = [self.label_pad_token_id] * len(\n",
        "                prompt_tokens[\"input_ids\"]\n",
        "            )\n",
        "            rejected_sequence_tokens[\"labels\"] = rejected_sequence_tokens[\"input_ids\"][:]\n",
        "            rejected_sequence_tokens[\"labels\"][: len(prompt_tokens[\"input_ids\"])] = [self.label_pad_token_id] * len(\n",
        "                prompt_tokens[\"input_ids\"]\n",
        "            )\n",
        "\n",
        "            for k, toks in {\n",
        "                \"chosen\": chosen_sequence_tokens,\n",
        "                \"rejected\": rejected_sequence_tokens,\n",
        "                \"prompt\": prompt_tokens,\n",
        "            }.items():\n",
        "                for type_key, tokens in toks.items():\n",
        "                    if type_key == \"token_type_ids\":\n",
        "                        continue\n",
        "                    batch[f\"{k}_{type_key}\"] = tokens\n",
        "\n",
        "        else:\n",
        "            chosen_tokens = self.tokenizer(\n",
        "                chosen, truncation=True, max_length=self.max_target_length, add_special_tokens=True\n",
        "            )\n",
        "            rejected_tokens = self.tokenizer(\n",
        "                rejected, truncation=True, max_length=self.max_target_length, add_special_tokens=True\n",
        "            )\n",
        "            prompt_tokens = self.tokenizer(\n",
        "                prompt, truncation=True, max_length=self.max_prompt_length, add_special_tokens=True\n",
        "            )\n",
        "\n",
        "            batch[\"chosen_labels\"] = chosen_tokens[\"input_ids\"]\n",
        "            batch[\"rejected_labels\"] = rejected_tokens[\"input_ids\"]\n",
        "            batch[\"prompt_input_ids\"] = prompt_tokens[\"input_ids\"]\n",
        "            batch[\"prompt_attention_mask\"] = prompt_tokens[\"attention_mask\"]\n",
        "\n",
        "            if self.model is not None and hasattr(self.model, \"prepare_decoder_input_ids_from_labels\"):\n",
        "                batch[\"rejected_decoder_input_ids\"] = self.model.prepare_decoder_input_ids_from_labels(\n",
        "                    labels=batch[\"rejected_labels\"]\n",
        "                )\n",
        "                batch[\"chosen_decoder_input_ids\"] = self.model.prepare_decoder_input_ids_from_labels(\n",
        "                    labels=batch[\"chosen_labels\"]\n",
        "                )\n",
        "\n",
        "        batch[\"prompt\"] = prompt\n",
        "        batch[\"chosen\"] = prompt + chosen\n",
        "        batch[\"rejected\"] = prompt + rejected\n",
        "        batch[\"chosen_response_only\"] = chosen\n",
        "        batch[\"rejected_response_only\"] = rejected\n",
        "\n",
        "        return batch\n",
        "\n",
        "    def collate(self, batch):\n",
        "        # first, pad everything to the same length\n",
        "        padded_batch = {}\n",
        "        for k in batch[0].keys():\n",
        "            if k.endswith(\"_input_ids\") or k.endswith(\"_attention_mask\") or k.endswith(\"_labels\"):\n",
        "                # print(f\"k: {k}\")\n",
        "                if self.is_encoder_decoder:\n",
        "                    to_pad = [torch.LongTensor(ex[k]) for ex in batch]\n",
        "\n",
        "                    if (k.startswith(\"prompt\")) and (k.endswith(\"input_ids\")):\n",
        "                        padding_value = self.tokenizer.pad_token_id\n",
        "                    elif k.endswith(\"_attention_mask\"):\n",
        "                        padding_value = 0\n",
        "                    elif (k.startswith(\"chosen\")) or (k.startswith(\"rejected\")) or (\"decoder\" in k):\n",
        "                        padding_value = self.label_pad_token_id\n",
        "                    else:\n",
        "                        raise ValueError(f\"Unexpected key in batch '{k}'\")\n",
        "                    padded_batch[k] = pad_sequence(to_pad, batch_first=True, padding_value=padding_value)\n",
        "                else:\n",
        "                    # adapted from https://stackoverflow.com/questions/73256206\n",
        "                    if \"prompt\" in k:\n",
        "                        to_pad = [torch.LongTensor(ex[k][::-1]) for ex in batch]\n",
        "                    else:\n",
        "                        # print(f\"k: {k}\")\n",
        "                        # for ex in batch:\n",
        "                            # print(f\"ex[k]: {ex[k]}\")\n",
        "                        to_pad = [torch.LongTensor(ex[k]) for ex in batch]\n",
        "                    if k.endswith(\"_input_ids\"):\n",
        "                        padding_value = self.tokenizer.pad_token_id\n",
        "                    elif k.endswith(\"_labels\"):\n",
        "                        padding_value = self.label_pad_token_id\n",
        "                    elif k.endswith(\"_attention_mask\"):\n",
        "                        padding_value = self.padding_value\n",
        "                    else:\n",
        "                        raise ValueError(f\"Unexpected key in batch '{k}'\")\n",
        "\n",
        "                    padded_batch[k] = pad_sequence(to_pad, batch_first=True, padding_value=padding_value)\n",
        "                    # for the prompt, flip back so padding is on left side\n",
        "                    if \"prompt\" in k:\n",
        "                        padded_batch[k] = padded_batch[k].flip(dims=[1])\n",
        "            else:\n",
        "                padded_batch[k] = [ex[k] for ex in batch]\n",
        "\n",
        "        return padded_batch\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        tokenized_batch = []\n",
        "\n",
        "        for feature in features:\n",
        "            prompt = feature[\"prompt\"]\n",
        "            chosen = feature[\"chosen\"]\n",
        "            rejected = feature[\"rejected\"]\n",
        "\n",
        "            batch_element = self.tokenize_batch_element(prompt, chosen, rejected)\n",
        "            tokenized_batch.append(batch_element)\n",
        "\n",
        "        # return collated batch\n",
        "        return self.collate(tokenized_batch)"
      ],
      "metadata": {
        "id": "kxwAStuJP1R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions for sequences\n",
        "\n",
        "# Compute GC content\n",
        "def batch_gc_values(codon_seqs):\n",
        "    gc_values = []\n",
        "    gc_counts = []\n",
        "    for seq in codon_seqs:\n",
        "      gc_val = gc_score(seq)\n",
        "      gc_cnt = gc_count(seq)\n",
        "      gc_values.append(gc_val)\n",
        "      gc_counts.append(gc_cnt)\n",
        "    return gc_values, gc_counts\n",
        "\n",
        "# GC content value\n",
        "def gc_score(sequence):\n",
        "  gc = dict()\n",
        "  for n in sequence:\n",
        "    if n in gc:\n",
        "      gc[n] += 1\n",
        "    else:\n",
        "      gc[n] = 1\n",
        "\n",
        "  gc_value = float(gc['G'] + gc['C'])/len(sequence)*100\n",
        "  return gc_value\n",
        "\n",
        "# Count of G and C\n",
        "def gc_count(sequence):\n",
        "  gc = dict()\n",
        "  for n in sequence:\n",
        "    if n in gc:\n",
        "      gc[n] += 1\n",
        "    else:\n",
        "      gc[n] = 1\n",
        "\n",
        "  gc_cnt = float(gc['G'] + gc['C'])\n",
        "  return gc_cnt\n",
        "\n",
        "def codon_tokenizable_seqs(seqs):\n",
        "    \"\"\" Convert seqs to codon tokenizable form \"\"\"\n",
        "    codon_seqs = []\n",
        "    for s in seqs:\n",
        "        codons = []\n",
        "        for i in range(0,len(s),3):\n",
        "            codons.append(s[i:i+3])\n",
        "        codon_seqs.append(\" \".join(codons))\n",
        "\n",
        "    return codon_seqs\n",
        "\n",
        "def read_fasta(fasta_path):\n",
        "    \"\"\" Read sequences from specified fasta file \"\"\"\n",
        "    from Bio import SeqIO\n",
        "    fasta_seqs = []\n",
        "    for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
        "        fasta_seqs.append(str(record.seq).upper())\n",
        "\n",
        "    return fasta_seqs\n",
        "\n",
        "def read_txt(filepath):\n",
        "    \"\"\" Read sequences from specified txt file \"\"\"\n",
        "    import pandas as pd\n",
        "    data = pd.read_csv(filepath, sep='\\t')\n",
        "    print(f'Seqs data:\\n {data.head()}')\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "OyoOtmS2RdsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import yaml\n",
        "\n",
        "import argparse\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "cU4KGAXwRerP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sequences(seqs_path):\n",
        "    \"\"\" Load sequences from the specified path \"\"\"\n",
        "    import json\n",
        "    with open(seqs_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    sequences = data['mdh_given_natural_sequences']\n",
        "    print(f\"Number of sequences: {len(sequences)}\")\n",
        "    print(sequences[0])\n",
        "\n",
        "    return sequences\n",
        "\n",
        "def filter_sequences(sequences):\n",
        "    \"\"\" Filter sequences with constraints \"\"\"\n",
        "    # 1. Check if \"ATG\" is not in start seq\n",
        "    rem = []\n",
        "    for s in sequences:\n",
        "        if s[:3] != 'ATG':\n",
        "            rem.append(s)\n",
        "    print(len(rem))\n",
        "\n",
        "    # 2. Remove seqs that don't have ATG as start seq\n",
        "    filt_seqs = list(set(sequences) - set(rem))\n",
        "    print(len(filt_seqs))\n",
        "\n",
        "    # 3. Check if \"ATG\" is not in start seq; there should be 0 at this point\n",
        "    rem = []\n",
        "    for s in filt_seqs:\n",
        "        if s[:3] != 'ATG':\n",
        "            rem.append(s)\n",
        "    print(len(rem))\n",
        "\n",
        "    # 4. Check if len of seq is divisible by 3\n",
        "    rem_l = []\n",
        "    for s in filt_seqs:\n",
        "        if len(s) % 3 != 0:\n",
        "            rem_l.append(s)\n",
        "    print(len(rem_l))\n",
        "\n",
        "    # 5. Remove seqs with len not divisible by 3\n",
        "    filt_l_seqs = list(set(filt_seqs) - set(rem_l))\n",
        "    print(len(filt_l_seqs))\n",
        "\n",
        "    # 6. Check if \"ATG\" is not start seq or len of seq is not divisible by 3; should be 0 at this point\n",
        "    check = []\n",
        "    for s in filt_l_seqs:\n",
        "        if (s[:3] != 'ATG') or (len(s)%3 != 0):\n",
        "            check.append(s)\n",
        "    print(len(check))\n",
        "\n",
        "    return filt_l_seqs\n",
        "\n",
        "def split_chosen_rejected(filtered_seqs, run_params):\n",
        "    \"\"\" Split sequences to 'chosen' and 'rejected' \"\"\"\n",
        "\n",
        "    # Split mdh seqs to 'chosen' and 'rejected' based on GC content\n",
        "    print(f'Chosen gc min.: {run_params[\"chosen_range_min\"]}')\n",
        "    print(f'Chosen gc max.: {run_params[\"chosen_range_max\"]}')\n",
        "    chosen = []\n",
        "    rejected = []\n",
        "    for s in filtered_seqs:\n",
        "        if gc_score(s) > run_params[\"chosen_range_min\"] and gc_score(s) < run_params[\"chosen_range_max\"]:\n",
        "            chosen.append(s)\n",
        "        else:\n",
        "            rejected.append(s)\n",
        "\n",
        "    print(f\"Number of chosen, rejected: {len(chosen)}, {len(rejected)}\")\n",
        "\n",
        "    num_samples = min(len(chosen), len(rejected))\n",
        "    print(f'Min. number of sampels: {num_samples}')\n",
        "\n",
        "    return chosen[:num_samples], rejected[:num_samples]\n",
        "\n",
        "def train_eval_split(seqs, test_size=0.05):\n",
        "    \"\"\" Split given list of sequences to train and eval sets \"\"\"\n",
        "    import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    seqs_train, seqs_eval = train_test_split(np.array(seqs),\n",
        "                                        random_state=104,\n",
        "                                        test_size=test_size,\n",
        "                                        shuffle=True)\n",
        "\n",
        "    return seqs_train, seqs_eval\n",
        "\n",
        "def prepare_dataset(seqs_path, run_params):\n",
        "    # Prepare train, eval datasets\n",
        "\n",
        "    # Load training sequences\n",
        "    sequences = load_sequences(seqs_path)\n",
        "\n",
        "    # Process sequences\n",
        "    filtered_sequences = filter_sequences(sequences)\n",
        "\n",
        "    # Split seqs to 'chosen' and 'rejected'\n",
        "    chosen, rejected = split_chosen_rejected(filtered_sequences, run_params)\n",
        "\n",
        "    # Convert chosen and rejected sets to codon tokenizable form (spaced as codons)\n",
        "    chosen_codon = codon_tokenizable_seqs(chosen)\n",
        "    rejected_codon = codon_tokenizable_seqs(rejected)\n",
        "\n",
        "    # Sanity check\n",
        "    _, gc_counts_chosen = batch_gc_values(chosen)\n",
        "    _, gc_counts_chosen_codon = batch_gc_values(chosen_codon)\n",
        "    _, gc_counts_rej = batch_gc_values(rejected)\n",
        "    _, gc_counts_rej_codon = batch_gc_values(rejected_codon)\n",
        "    assert gc_counts_chosen == gc_counts_chosen_codon, f\"GC counts do not match 'chosen' set\"\n",
        "    assert gc_counts_rej == gc_counts_rej_codon, f\"GC counts do not match 'rejected' set\"\n",
        "\n",
        "    # Split chosen and rejected to train and eval set with given test_size\n",
        "    chosen_train, chosen_eval = train_eval_split(chosen_codon, test_size=0.05)\n",
        "    rejected_train, rejected_eval = train_eval_split(rejected_codon, test_size=0.05)\n",
        "\n",
        "    print(f\"Number of chosen train, eval, (total): {len(chosen_train)}, {len(chosen_eval)}, ({len(chosen_train)+len(chosen_eval)})\")\n",
        "    print(f\"Number of rejected train, eval, (total): {len(rejected_train)}, {len(rejected_eval)}, ({len(rejected_train)+len(rejected_eval)})\")\n",
        "\n",
        "    # Prepare train dataset\n",
        "    train_dict = dict()\n",
        "    train_dict['chosen'] = list(chosen_train)\n",
        "    train_dict['rejected'] = list(rejected_train[:len(chosen_train)]) # require same number of entries in each category\n",
        "    train_ds = Dataset.from_dict(train_dict)\n",
        "    print(f\"Train dataset: {train_ds}\")\n",
        "\n",
        "    # Prepare eval dataset\n",
        "    eval_dict = dict()\n",
        "    eval_dict['chosen'] = list(chosen_eval)\n",
        "    eval_dict['rejected'] = list(rejected_eval[:len(chosen_eval)]) # require same number of entries in each category\n",
        "    eval_ds = Dataset.from_dict(eval_dict)\n",
        "    print(f\"Eval dataset: {eval_ds}\")\n",
        "\n",
        "    # Add prompt feature\n",
        "    train_dataset = train_ds.map(split_codon_prompt_and_responses)\n",
        "    eval_dataset = eval_ds.map(split_codon_prompt_and_responses)\n",
        "\n",
        "    return train_dataset, eval_dataset\n",
        "\n",
        "def get_data_collator(tokenizer):\n",
        "    \"\"\" Get data collator \"\"\"\n",
        "    data_collator = DPODataCollatorWithPadding(\n",
        "        tokenizer,\n",
        "        max_length=512,\n",
        "        max_prompt_length=128,\n",
        "        label_pad_token_id=-100,\n",
        "        padding_value=0,\n",
        "        truncation_mode='keep_start',\n",
        "        is_encoder_decoder=None,\n",
        "        max_target_length=128,\n",
        "    )\n",
        "\n",
        "    return data_collator\n",
        "\n",
        "def load_tokenizer(tokenizer_file):\n",
        "    \"\"\" Load pretrained tokenizer from given path \"\"\"\n",
        "    from transformers import AutoTokenizer\n",
        "    from transformers import PreTrainedTokenizerFast\n",
        "    from tokenizers import Tokenizer\n",
        "    tokenizer = PreTrainedTokenizerFast(\n",
        "                tokenizer_object=Tokenizer.from_file(str(tokenizer_file))\n",
        "            )\n",
        "    # tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "\n",
        "    return tokenizer\n",
        "\n",
        "def load_model(saved_model_path):\n",
        "    \"\"\" Load pretrained model from the model path \"\"\"\n",
        "    from transformers import GPTNeoXForCausalLM, AutoModelForCausalLM\n",
        "\n",
        "    # Load model\n",
        "        # config_file_path = ''\n",
        "        # config_mdh = AutoConfig.from_pretrained(config_file_path, max_position_embeddings=512)\n",
        "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
        "    model_ref = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
        "\n",
        "    return model, model_ref\n",
        "\n",
        "def print_run_params(run_params):\n",
        "    \"\"\" Print run params \"\"\"\n",
        "    print(f'beta: {run_params[\"beta\"]}')\n",
        "    print(f'learning rate: {run_params[\"lr\"]}')\n",
        "    print(f'training steps: {run_params[\"steps\"]}')\n",
        "    print(f'batch size: {run_params[\"batch_size\"]}')\n",
        "    print(f'chosen property: {run_params[\"chosen_property\"]}')\n",
        "    if run_params[\"chosen_property\"] == 'gc':\n",
        "        print(f'gc range: [{run_params[\"chosen_range_min\"]}, {run_params[\"chosen_range_max\"]}]')"
      ],
      "metadata": {
        "id": "NLrWchN_RnQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E7ri9rdAXcmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_training(run_params):\n",
        "\n",
        "    seqs_path = '/content/drive/MyDrive/mdh_data/mdh_given_natural_sequences.json'\n",
        "    tokenizer_file = '/content/drive/MyDrive/codon_wordlevel_100vocab.json'\n",
        "\n",
        "    saved_model_path = run_params['ref_model']\n",
        "    # saved_model_path = '/lus/eagle/projects/RL-fold/gdharuman/sc23/test_models/mdh-r_checkpoints/model_gptneox_25M_mdh-r_epochs-10.pt'\n",
        "\n",
        "    out_dir = '/content/runs'\n",
        "    run_tag = f'{run_params[\"chosen_property\"]}_{int(run_params[\"chosen_range_min\"])}-{int(run_params[\"chosen_range_max\"])}'\n",
        "\n",
        "    # Prepare dataset\n",
        "    train_dataset, eval_dataset = prepare_dataset(seqs_path, run_params)\n",
        "    print(f\"final train dataset: {train_dataset}\")\n",
        "    print(f\"final eval dataset: {eval_dataset}\")\n",
        "    print(f\"train_dataset[0]: {train_dataset[0]}\")\n",
        "    print(f\"eval_dataset[0]: {eval_dataset[0]}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = load_tokenizer(tokenizer_file)\n",
        "    print(f\"[PAD] token_id: {tokenizer.pad_token_id}\")\n",
        "\n",
        "    # Get data collator and sanity check\n",
        "    data_collator = get_data_collator(tokenizer)\n",
        "    _ = data_collator(eval_dataset)\n",
        "\n",
        "    # Get device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('device:', device)\n",
        "\n",
        "    # Load fine-tuned model\n",
        "    model, model_ref = load_model(saved_model_path)\n",
        "    print(f\"model.device, model_ref.device: {model.device}, {model_ref.device}\")\n",
        "\n",
        "    # Get date time\n",
        "    now = datetime.now()\n",
        "    dt_string = now.strftime(\"%d%m%y-%H%M%S\")\n",
        "\n",
        "    # Create run directory\n",
        "    if run_params[\"epochs\"] is not None:\n",
        "        run_dir = out_dir + f'/beta-{run_params[\"beta\"]}_lr-{run_params[\"lr\"]}_bs-{run_params[\"batch_size\"]}_steps-{run_params[\"epochs\"]}_{run_tag}_{dt_string}'\n",
        "    else:\n",
        "        run_dir = out_dir + f'/beta-{run_params[\"beta\"]}_lr-{run_params[\"lr\"]}_bs-{run_params[\"batch_size\"]}_steps-{run_params[\"steps\"]}_{run_tag}_{dt_string}'\n",
        "    Path(run_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Update and write run params to yaml file\n",
        "    run_params[\"run_tag\"] = dt_string # add datetime to run_params\n",
        "    with open(run_dir+'/run_config.yml', 'w') as yaml_file:\n",
        "        yaml.dump(run_params, yaml_file, default_flow_style=False)\n",
        "\n",
        "    # Initialize training arguments\n",
        "    # training_args = TrainingArguments(\n",
        "    #     per_device_train_batch_size=run_params[\"batch_size\"],\n",
        "    #     # max_steps=run_params[\"steps\"],\n",
        "    #     num_train_epochs=run_params[\"epochs\"],\n",
        "    #     remove_unused_columns=False,\n",
        "    #     gradient_accumulation_steps=1,\n",
        "    #     learning_rate=run_params[\"lr\"],\n",
        "    #     evaluation_strategy=\"steps\",\n",
        "    #     output_dir=run_dir,\n",
        "    #     report_to=\"wandb\",\n",
        "    # )\n",
        "\n",
        "    training_args = DPOConfig(\n",
        "    output_dir='/content/runs',\n",
        "    beta=0.1,\n",
        "    per_device_train_batch_size=run_params[\"batch_size\"],\n",
        "    num_train_epochs=run_params[\"epochs\"],\n",
        "    remove_unused_columns=False,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=run_params[\"lr\"],\n",
        "    evaluation_strategy=\"steps\",\n",
        "    report_to=\"wandb\",\n",
        "    )\n",
        "\n",
        "    # Initialize the DPO trainer\n",
        "    dpo_trainer = DPOTrainer(\n",
        "        model,\n",
        "        model_ref,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        # beta=run_params[\"beta\"],\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        max_length=512,\n",
        "        # max_target_length=128,\n",
        "        max_prompt_length=128,\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    dpo_trainer.train()"
      ],
      "metadata": {
        "id": "zzqbNnjSRz5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_params = dict()\n",
        "run_params[\"beta\"] = 0.1\n",
        "run_params[\"lr\"] = 5e-5\n",
        "run_params[\"steps\"] = 100\n",
        "run_params[\"epochs\"] = 10\n",
        "run_params[\"chosen_property\"] = 'gc'\n",
        "run_params[\"chosen_range_min\"] = 45.0\n",
        "run_params[\"chosen_range_max\"] = 55.0\n",
        "run_params[\"batch_size\"] = 8\n",
        "run_params[\"ref_model\"] = '/content/drive/MyDrive/mdh_data/model_mdh_last.pt'\n",
        "\n",
        "# Print run params\n",
        "print_run_params(run_params)\n",
        "\n",
        "perform_training(run_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "90435ffd018449798d7bdcb77e9831a4",
            "f31c623f6be24746bfd919cb5602d233",
            "d0cfa06a007f489faf2311148d7630c6",
            "916c0193a6b14306bc14e5809a0f967c",
            "8fb997661795465a94b7790a6ba07ae9",
            "7c4bb65bb5ba4e678f10fe0b80d6c0ae",
            "5317ff4f5ec842fbb315750f49787ede",
            "727db1faca984d8f8849f7c5ae7eeff9",
            "2b35c6bb498542fab5fb6ee0069cfc3b",
            "31e342c30dfc4253a95c742b7170e186",
            "66266efe71b54d6ab50ee20fca716ddc",
            "5d20a77261d84f7ba730085e68b9f5d5",
            "9a9843240adf432cb9bd9b8c0dfe032e",
            "2e59ca259a4447a5bf41280503f22f4a",
            "980eb06d64f5456697a11c359269c044",
            "496e945dd7a24b1e9843c07294ea3ae4",
            "40a5800165674e738bfac918410cb3b7",
            "172b70a8c3794b77b51011456fd6350e",
            "b71188233fc341af9c39782aa3b8a732",
            "c8c05151323f42a6ac8adae91a0754bf",
            "7c8f95d658e14d4694181a020f4c4b2d",
            "9b13ac9807c14ff8997fc8f23c302753",
            "98e7f0aef7a343feb360832f8583b69e",
            "003a8b6fcb424f3ab260bb8466aef801",
            "c1e663d874dc4f1a83b5419244b74ba4",
            "25157aa3f34a43ca8b4098b6311619b1",
            "ce8c9f7c49f8474092c469e38d4a9a74",
            "fb1f4a2751de4a888baaabb0623fe2d6",
            "7da73e9ca87d47679e3fc4a467671f26",
            "0c20f59577734c309997162c96e58e1c",
            "0cf2bf21baeb4c9ca85c7b252c6e03ec",
            "c016193de88a4fdfad1b97f462584056",
            "d74fe787e62d4065b4d69327fde030d5",
            "5ab939bec7d74c9ca7ecf00f93db8b25",
            "14f7ca47dcc1478689c4a80cd6b0ad76",
            "0acd9bfa52494e4c92fc037d3f4effe1",
            "e88225081f8042f1aafc5d09606df089",
            "4958d4aa49d046278c50c90592d80375",
            "197a6789b3c34ec59ca1192f84ce4b79",
            "298ea1dea85643daaceeb35d839f3a97",
            "30ac0970f29446bfbf0eaa9ace6d8db0",
            "bfa18cda1574470ea3e190d5b05f9ffc",
            "50bb5ab875ef478892cc9565b0054ca3",
            "8d6f954ce14246818a5d9c582072af32"
          ]
        },
        "id": "YJGMWmBeSPGx",
        "outputId": "307cd3b9-8642-4b2f-e5f9-ea9e696ca10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beta: 0.1\n",
            "learning rate: 5e-05\n",
            "training steps: 100\n",
            "batch size: 8\n",
            "chosen property: gc\n",
            "gc range: [45.0, 55.0]\n",
            "Number of sequences: 36631\n",
            "ATGAGCAAGGTCACCGTCGTAGGGGCCGGCAAGTACGGATCAACCACCGCCATGCGGCTCGCTGAAGCCGACATCGTCGACGAGGTCGTCATGACCGACATTGTCGAGGGTCTACCCCAGGGCCTGGCGCTCGATATCAATCAGTCGCGGCCGCTGCTCGGCTACCGGACCGTCATCACCGGTTCGAACGACTACGCCGCCACTGCCGGCAGCGATGTCGTGGTCATCACCGCCGGGTTGCCGCGCAAGCCAGGCATGAGTCGCATGGACCTCCTCGAGGTCAATGCCAAGATCGTCAAGGACGTCACCGTCCAGATAGCCGAGCATTCGCCGGACGCGGTCATCATCAACGTCACGAACCCGCTCGATCACATGACAACCCTGGCGGCGGAAGTATCCGGCTTCGACACCCGCCGGGTCATGGGACAGGCAGGCATGCTCGACTCCGCTCGTTTCGCTCATTTCATCGCAGAAGTGACCGGTGCCGACATCATGGACGTCGAGGCTCTTACCCTCGGCAGCCACGGAGAGACCATGGTCCCGGTTCCGTCACAAACCAAGGTGGGGGGCAAACTCCTCGCCGATCTCGTCGATGCCGACGCCGTCGAGTCGCTCGTCGACCGGACCCGCAAGGGTGGGGCCGAGGTTGTTGCGCTCCTCAAGACCGGCAGCGCCTATTACGCCCCCTCGGCGGCTGCCGCCAAGATGGTCGAAGCCGTCATTGGAGATACCGGCGAGGTGATGCCGGTATGTGCCTGGATGAGTGGCGAGTACGGGATCTCCGACGTATACCTCGGTGTTCCAGCAAGTCTCGGCAAAGAGGGCGTGAAGGAGATCGTCGAACTCCCGCTCACCGACACTGAGGCAACCGCGCTGTCTGAAGCTGCGGCGTCCGTGAAGGAAAAGGTCGACGAGCTGCACGAGTTGGATCTGGGATAG\n",
            "3468\n",
            "33154\n",
            "0\n",
            "4\n",
            "33150\n",
            "0\n",
            "Chosen gc min.: 45.0\n",
            "Chosen gc max.: 55.0\n",
            "Number of chosen, rejected: 8172, 24978\n",
            "Min. number of sampels: 8172\n",
            "Number of chosen train, eval, (total): 7763, 409, (8172)\n",
            "Number of rejected train, eval, (total): 7763, 409, (8172)\n",
            "Train dataset: Dataset({\n",
            "    features: ['chosen', 'rejected'],\n",
            "    num_rows: 7763\n",
            "})\n",
            "Eval dataset: Dataset({\n",
            "    features: ['chosen', 'rejected'],\n",
            "    num_rows: 409\n",
            "})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7763 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90435ffd018449798d7bdcb77e9831a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/409 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d20a77261d84f7ba730085e68b9f5d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final train dataset: Dataset({\n",
            "    features: ['chosen', 'rejected', 'prompt'],\n",
            "    num_rows: 7763\n",
            "})\n",
            "final eval dataset: Dataset({\n",
            "    features: ['chosen', 'rejected', 'prompt'],\n",
            "    num_rows: 409\n",
            "})\n",
            "train_dataset[0]: {'chosen': ' GTC CTC GGC GCT GCT GGT GGT ATT GGC CAG GCG CTT GCC CTA CTA CTG AAA ACC CAA CTG CCT TCA GGC TCA GAA CTC TCC CTG TAC GAT ATT GCT CCG GTA ACC CCA GGT GTG GCG GTT GAC CTG AGC CAC ATC CCA ACC GCG GTG AAA ATT AAA GGC TTC TCT GGC GAA GAT GCA CGT CCA GCG CTG CAA GGT GCT GAC GTG GTG CTC ATC TCT GCG GGC GTC GCA CGT AAG CCG GGT ATG GAT CGT TCT GAC CTG TTT AAC GTC AAC GCT GGC ATC GTC AAA AAT CTG GTT CAA CAG ATT GCT GAA ACC TGC CCG AAA GCG TGC GTG GGT ATC ATC ACC AAC CCG GTG AAT ACC ACG GTG GCC ATT GCG GCA GAA GTG CTG AAA AAA GCC GGT GTT TAC GAT AAG AAC AAG CTG TTT GGC GTG ACC ACG CTG GAT ATT ATC CGC TCC AAT ACC TTT GTT GCT GAA CTG AAA GGC AAG TCA CCT GCT GAG ATC GAG GTT CCG GTT ATC GGA GGC CAC TCA GGC GTG ACC ATT CTG CCT CTG CTG TCT CAG ATC CCA GGC GTT AGC TTC TCC GAG CAG GAA GTC GCT GAC CTG ACC AAA CGC ATC CAG AAC GCG GGC ACC GAA GTG GTG GAA GCG AAG GCG GGT GGC GGA TCG GCA ACC CTG TCC ATG GGC CAG GCT GCT GCA CGT TTT GGT CTG TCT CTG GTG CGT GCG CTG CAG GGC GAG AAA GGC GTA GTG GAA TGT GCG TAT GTT GAA GGC GAC GGT GAG CAT GCA CGT TTC TTC TCT CAG CCG CTG CTG CTG GGT AAA AAC GGT ATT GAA GAA CGT CAG TCT ATC GGC ACG CTG AGC GCG TTT GAA CAA AAT GCG ATG GAA GGT ATG CTG GAT ACG CTG AAG AAA GAT ATC ACC TTG GGC GAA GAG TTC GTT AAC AAG TAA', 'rejected': ' GTT GTC GGG GCC GGC AAC GTG GGC GCT ACC TGC GCC GAC GTG CTC GCC ACC CGT GAA ATC GCC AAC GAA GTC GTG CTG GTC GAC ATC AAA GAG GGC ATT GCC GAA GGC AAA GCC TTG GAC ATC TGG CAG AAA GCG CCG ATT ATC GGC TAC GAC TCG CGC ACC GTG GGC GTC ACC AAC GAC TAC GCC CGC ACC GCC GGC TCG GAG GTG GTG GTC ATC ACC TCG GGC CTG CCC CGC AAG CCC GGC ATG AGC CGC GAC GAC CTG ATT GCC ACC AAC GCC GGT ATC GTG AAA TCG GTG ACC GAG CAG GTG GTG GCC CAC TCG CCC AAC GCC ATT ATC ATC GTT GTC AGC AAC CCG CTC GAC GTG ATG ACC TAC CAG GCC CAC CTC ACC GCC AAG CTG CCC CGC GAG AAG GTG TTC GGC ATG GCC GGC ATC CTC GAC ACG GCC CGC TAC CGC GCC TTT CTG GCC GAG GCC CTG AAC GTG AGC CCG AAA GAC ATC CAG GCG GTG CTG ATG GGC GGC CAC GGC GAC ACT ATG GTG CCC CTG CCC CGC TAC ACC ACC GTG GGC GGC ATT CCC GTC ACC GAA TTG ATT TCT AAA GAG AAG CTC GAC GCC ATC GTG CAG CGC ACC GCC GTG GGC GGC GGC GAG CTG GTG AAG CTC ATG GGC ACC TCG GCC TGG TAC GCA CCC GGC GCG GCC GCC GCC CAA ATG GTG GAG GCC ATC GTG CGC GAC CAG CGC CGC GTG TTC CCG GTG TGC CTG GAG CTG CAA GGC GAG TAC GGC ATC AAC GGC GTG TAC CTG GGG GCC CCG GTC ATC CTG GGC AAA AAC GGC GTG GAG CGC GTG ATT GAG CTA AAG CTC AAC GAC GAG GAA AAA GCC ATG CTC GAA ACC TCG CGC GGC CAC GTA AAG GAG GTG ATG GAC GCG CTG GAC AAG ATG GGC CAG CCG GCG TAG', 'prompt': 'ATG AAA GTT GCA'}\n",
            "eval_dataset[0]: {'chosen': ' GTA GTA GGT GCC GGT GCC GTT GGA GCC ACC TGT GCC GAT AAT ATC GCC CGT AAG GAA TTA TGC AAT GAA CTG GTT TTA CTC GAT ATC AAA GAA GGT ATT GCA GAA GGC AAG GCC CAG GAT ATG ATG CAG ACC GCT ACC CTG CTT GGC TTC GAT ACC AAG ATT ACC GGT AGC ACC AAT GAC TAC AGC AAA ACC GCG AAC AGT GAT GTA GTG GTG ATT ACT TCG GGC TTA CCC CGT AAA CCG GGT ATG ACC CGT GAA GAA CTG ATT GGT GTG AAT GCC GGT ATC GTT AAA GGT GTT TGT GAG AAT ATC CTG AAG CAT TCT CCC AAT GCC ATC ATC ATT GTG ATC AGT AAT CCG ATG GAT ACG ATG ACT TAT CTC GCT ATG CAG TCA ACC GGT TTA CCC AAG CAC CGC ATC ATC GGT ATG GGT GGT ACC CTC GAC AGC AGC CGC TTT AAA TAC CAG CTG AGC CAG CAC CTG GGT TGC AGT CCG GCT GAC CTG AAT GCC GTT GTG GTA GGT GGA CAT GGA GAT ACT ACC ATG ATT CCG CTG ATC CGT CTG GCA ACC TGG AAC AGC ACC CCT GTT ACC AAT TTC CTG AGT GCT GAG CAG CAG GAG AAA ATT GTA AAA GAC ACG ATG GTA GGT GGT GCT ACT TTA ACT GCA CTG ATT GGT ACC TCT GCC TGG TAT GCA CCG GGA GCA GCC GGA GCT GCG TTG GTT GAA TCT ATC CTG CGG GAT GAA AAG AAA CTC TTT ACC TGT TGT GTG GCT TTG GAT GGT GAA TAT GGT CAG AAA GAT ATC TGT CTC GGT GTA CCG GTG ATC ATT GGA AAA AAC GGA TGG GAG AAA ATC CTT GAC TTC CAG TTA AAT GAA ACC GAG CAG GCT GCC TTT AAT AAA AGT GCG GAT GCG GTG AGA AGT ATG AAT GAT GTG TTG AAG ACT TTA TAA', 'rejected': ' GTT ACC GTT GTT GGC GCG GGG AAT GTG GGG GCC ACC TGT GCC GAG CGG GTG GCC GAA AAG GGC TAC GCT GAT GTC GTC CTG GTG GAC ATC GTC GAG GGC CTG CCA CAA GGC AAG GCC CTG GAC CTG CTC CAA TCC GGT CCT ATC GTC GGG TTC GAC ACC AGC GTG ACT GGC TCC AAC TCC TAT GAG GCG ACA GAT CAC TCC GAT ATC GTG GTC ATC ACG TCT GGT GTC GCG CGC AAG CCG GGA ATG AGC CGC GAT GAC CTT CTG TTG ACG AAC AAG AAG ATC GTA CAG GCG GTC ACG GAG TCC GTG GTC AGG GTT TCG CCC GAC TGC ATC ATA ATT GTC GTG ACC AAT CCG CTC GAC GCC ATG ACG CAA TTG GCG CTG CAC GCA AGC AGA TTC CCA AAG CAC AGG GTG ATG GGG CAG TCC GGC GTG CTG GAC AGC GCT CGT TTC AGG ACT TTC GTG GCA GCG GAG ATG GGA GTC TCA GTA CAT GAT GTC TAT GCA TGC GTC CTG GGC GGG CAC GGC GAC ACC ATG GTG CTC TTG CCA CGT TAT TCA ACG GTC GGT GGG GTG CCG ATA ACC GAG CTG TTG CCG AAG TCG ACC ATT GAC AGG CTT GTG GCG CGG ACT GTG AAC GGC GGC GGC GAA ATA GTG GCA TTG CTG AAA ACC GGC AGC GCA TTC TAC GCG CCT GGC GCG GCG GCG GCG CAG ATG GTT GAC GCA ATG CTT ATG GAC CGC AAG AAG ATA CTG CCG TGC GCG ACG CTG CTG GAA GGC GAG TAT GGC ATG ACG GGC CTC GTC GTC GGC GTC CCT GTT AGG CTG GGG CGA AAG GGT GTG GAG CAG GTC ATC GAG CTG AAG CTG ACC GCG GAG GAG AGC GCA GCC CTC AGA CGG TCC GGT GAT GCA GTG AAA GAG TTG CTC TCG GTG ATG AAG CTC AAT TGA', 'prompt': 'ATG AAA GTA ACT'}\n",
            "[PAD] token_id: 3\n",
            "device: cuda\n",
            "model.device, model_ref.device: cpu, cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_length, max_prompt_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in DPOTrainer, please use the DPOConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:389: UserWarning: You passed `max_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:402: UserWarning: You passed `max_prompt_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7763 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98e7f0aef7a343feb360832f8583b69e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/409 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ab939bec7d74c9ca7ecf00f93db8b25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240712_185612-ix1o9nza</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gadh/huggingface/runs/ix1o9nza' target=\"_blank\">/content/runs</a></strong> to <a href='https://wandb.ai/gadh/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/gadh/huggingface' target=\"_blank\">https://wandb.ai/gadh/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/gadh/huggingface/runs/ix1o9nza' target=\"_blank\">https://wandb.ai/gadh/huggingface/runs/ix1o9nza</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9710' max='9710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9710/9710 26:58, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rewards/chosen</th>\n",
              "      <th>Rewards/rejected</th>\n",
              "      <th>Rewards/accuracies</th>\n",
              "      <th>Rewards/margins</th>\n",
              "      <th>Logps/rejected</th>\n",
              "      <th>Logps/chosen</th>\n",
              "      <th>Logits/rejected</th>\n",
              "      <th>Logits/chosen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.084800</td>\n",
              "      <td>0.003970</td>\n",
              "      <td>-2.528712</td>\n",
              "      <td>-13.351259</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.822550</td>\n",
              "      <td>-466.884155</td>\n",
              "      <td>-353.844177</td>\n",
              "      <td>-0.907256</td>\n",
              "      <td>-0.912630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>0.002662</td>\n",
              "      <td>-3.434631</td>\n",
              "      <td>-17.827110</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>14.392477</td>\n",
              "      <td>-511.642639</td>\n",
              "      <td>-362.903351</td>\n",
              "      <td>-0.909491</td>\n",
              "      <td>-0.928923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.004292</td>\n",
              "      <td>-3.701540</td>\n",
              "      <td>-19.475037</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>15.773498</td>\n",
              "      <td>-528.121887</td>\n",
              "      <td>-365.572449</td>\n",
              "      <td>-0.886685</td>\n",
              "      <td>-0.906602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.004476</td>\n",
              "      <td>-3.857410</td>\n",
              "      <td>-20.309338</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>16.451931</td>\n",
              "      <td>-536.464905</td>\n",
              "      <td>-367.131165</td>\n",
              "      <td>-0.875277</td>\n",
              "      <td>-0.897353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004403</td>\n",
              "      <td>-3.954470</td>\n",
              "      <td>-20.608116</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>16.653645</td>\n",
              "      <td>-539.452698</td>\n",
              "      <td>-368.101746</td>\n",
              "      <td>-0.871456</td>\n",
              "      <td>-0.894028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004544</td>\n",
              "      <td>-4.075648</td>\n",
              "      <td>-20.946306</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>16.870657</td>\n",
              "      <td>-542.834595</td>\n",
              "      <td>-369.313538</td>\n",
              "      <td>-0.868154</td>\n",
              "      <td>-0.891260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004858</td>\n",
              "      <td>-4.193683</td>\n",
              "      <td>-21.392702</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>17.199018</td>\n",
              "      <td>-547.298523</td>\n",
              "      <td>-370.493866</td>\n",
              "      <td>-0.863146</td>\n",
              "      <td>-0.886994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004958</td>\n",
              "      <td>-4.317677</td>\n",
              "      <td>-21.798922</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>17.481245</td>\n",
              "      <td>-551.360779</td>\n",
              "      <td>-371.733826</td>\n",
              "      <td>-0.858676</td>\n",
              "      <td>-0.883212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005298</td>\n",
              "      <td>-4.441584</td>\n",
              "      <td>-22.245014</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>17.803431</td>\n",
              "      <td>-555.821716</td>\n",
              "      <td>-372.972870</td>\n",
              "      <td>-0.853492</td>\n",
              "      <td>-0.878771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005376</td>\n",
              "      <td>-4.553698</td>\n",
              "      <td>-22.558617</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>18.004919</td>\n",
              "      <td>-558.957703</td>\n",
              "      <td>-374.094055</td>\n",
              "      <td>-0.850195</td>\n",
              "      <td>-0.875942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005682</td>\n",
              "      <td>-4.669851</td>\n",
              "      <td>-23.006418</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>18.336565</td>\n",
              "      <td>-563.435730</td>\n",
              "      <td>-375.255554</td>\n",
              "      <td>-0.845187</td>\n",
              "      <td>-0.871810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005849</td>\n",
              "      <td>-4.783114</td>\n",
              "      <td>-23.364458</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>18.581343</td>\n",
              "      <td>-567.016174</td>\n",
              "      <td>-376.388184</td>\n",
              "      <td>-0.841585</td>\n",
              "      <td>-0.868855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005989</td>\n",
              "      <td>-4.884422</td>\n",
              "      <td>-23.687054</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>18.802631</td>\n",
              "      <td>-570.242065</td>\n",
              "      <td>-377.401306</td>\n",
              "      <td>-0.837771</td>\n",
              "      <td>-0.865621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006225</td>\n",
              "      <td>-4.984350</td>\n",
              "      <td>-24.014544</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>19.030193</td>\n",
              "      <td>-573.517029</td>\n",
              "      <td>-378.400543</td>\n",
              "      <td>-0.834439</td>\n",
              "      <td>-0.862838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006502</td>\n",
              "      <td>-5.085260</td>\n",
              "      <td>-24.366243</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>19.280981</td>\n",
              "      <td>-577.033936</td>\n",
              "      <td>-379.409668</td>\n",
              "      <td>-0.830271</td>\n",
              "      <td>-0.859368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006598</td>\n",
              "      <td>-5.166870</td>\n",
              "      <td>-24.623394</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>19.456524</td>\n",
              "      <td>-579.605530</td>\n",
              "      <td>-380.225739</td>\n",
              "      <td>-0.827785</td>\n",
              "      <td>-0.857347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006701</td>\n",
              "      <td>-5.240672</td>\n",
              "      <td>-24.849525</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>19.608852</td>\n",
              "      <td>-581.866821</td>\n",
              "      <td>-380.963745</td>\n",
              "      <td>-0.825431</td>\n",
              "      <td>-0.855381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006845</td>\n",
              "      <td>-5.296723</td>\n",
              "      <td>-25.033043</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>19.736320</td>\n",
              "      <td>-583.701965</td>\n",
              "      <td>-381.524261</td>\n",
              "      <td>-0.823641</td>\n",
              "      <td>-0.853982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006868</td>\n",
              "      <td>-5.325740</td>\n",
              "      <td>-25.129526</td>\n",
              "      <td>0.997596</td>\n",
              "      <td>19.803785</td>\n",
              "      <td>-584.666748</td>\n",
              "      <td>-381.814453</td>\n",
              "      <td>-0.822730</td>\n",
              "      <td>-0.853245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1473: UserWarning: prediction_step is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:1400: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l5AOTPp_TFEa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}