{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Retrieval Augmented Generation (RAG)"
      ],
      "metadata": {
        "id": "jGpjFGh2qX2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "*   Motivation for RAG\n",
        "*   Idea behind RAG\n",
        "*   Advantages and Disadvantages\n",
        "*   Implementation to augment question + answer\n",
        "*   Advanced applications\n"
      ],
      "metadata": {
        "id": "ACA8jfiCDuOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imagine you went to live under a rock on August 2006. When you come out in 2024, you are asked how many planets revolve around the sun. What would you say?...\n",
        "![pluto](https://github.com/architvasan/LLMWorkshop/blob/main/rag_images/pluto_planets.jpeg?raw=1)\n",
        "\n",
        "This is similar to LLMs which are trained with data until a certain point and then asked questions on data they are not trained on. Understandably, LLMs will either be unable to answer or simply hallucinate a probably wrong answer."
      ],
      "metadata": {
        "id": "r5YjAA14ih8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What can be done?\n",
        "\n",
        "Have the LLM go to the library using **Research Augmented Generation (RAG)**!"
      ],
      "metadata": {
        "id": "W3HmhY-rl29V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG involves adding your own data (via a retrieval tool) to the prompt that you pass into a large language model.\n"
      ],
      "metadata": {
        "id": "PXtqMcK1nAv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![rag architecture](https://github.com/architvasan/LLMWorkshop/blob/main/rag_images/rag-overview.original.png?raw=1)\n",
        "Image credit: https://scriv.ai/guides/retrieval-augmented-generation-overview/"
      ],
      "metadata": {
        "id": "GAGt5yQVrz0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG has been shown to improve LLM prediction accuracy without needing to increase parameter size.\n",
        "\n",
        "![rag architecture](https://github.com/architvasan/LLMWorkshop/blob/main/rag_images/rag_acc_v_size.png?raw=1)\n",
        "\n",
        "*Image credit: Yu, Wenhao. \"Retrieval-augmented generation across heterogeneous knowledge.\" Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Student Research Workshop. 2022.*"
      ],
      "metadata": {
        "id": "y6N4A87lt3Wq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG also increases explainability by giving the source for information.\n",
        "\n",
        "![rag architecture](https://github.com/architvasan/LLMWorkshop/blob/main/rag_images/rag_source_locator.png?raw=1)\n",
        "\n",
        "Image credit: https://ai.stanford.edu/blog/retrieval-based-NLP/"
      ],
      "metadata": {
        "id": "nDcwB4BMyUQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advantages and Disadvantages\n",
        "\n",
        "### Advantages\n",
        "\n",
        "*   Provides domain specific context\n",
        "*   Improves predictive performance and reduces hallucinations\n",
        "*   Does not increase model parameters\n",
        "*   Less labor intensive than fine-tuning LLMs\n",
        "\n",
        "### Disadvantages\n",
        "\n",
        "*   May introduce latency since we are adding a relatively costly search step\n",
        "*   If your dataset includes private information, you may inadvertently expose another user with this information.\n",
        "*   The data you want to use needs to be curated and you should decide how the data should be accessed. This adds time for the initial set-up.\n"
      ],
      "metadata": {
        "id": "QRUJ2eQvJIAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementation"
      ],
      "metadata": {
        "id": "s42Iqfmjy-1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Install + load relevant modules:\n",
        "*   langchain\n",
        "*   torch\n",
        "*   transformers\n",
        "*   sentence-transformers\n",
        "*   datasets\n",
        "*   faiss-cpu  \n",
        "*   pypdf\n",
        "*  unstructure[pdf]\n",
        "*  huggingface_hub (add hf_token)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rVkTgnU80jjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.1.5\n",
        "!pip install --quiet langchain_experimental\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install pypdf\n",
        "!pip install sentence-transformers\n",
        "!pip install unstructured==0.12.3\n",
        "!pip install unstructured[pdf]==0.12.3\n",
        "!pip install tiktoken\n",
        "!pip install huggingface_hub\n",
        "from huggingface_hub import login\n",
        "\n",
        "hf_token = \"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\"\n",
        "login(token=hf_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "c1uDuyDLd1Xi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8699f0ff-40b2-4b0c-ef17-ecf62de61f0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.1.5\n",
            "  Downloading langchain-0.1.5-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.5)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.5)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.17 (from langchain==0.1.5)\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain==0.1.5)\n",
            "  Downloading langchain_core-0.1.38-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.2/279.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain==0.1.5)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.5)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.5)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.5)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community<0.1,>=0.0.17 (from langchain==0.1.5)\n",
            "  Downloading langchain_community-0.0.30-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.26-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_community-0.0.23-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.22-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.21-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1.16 (from langchain==0.1.5)\n",
            "  Downloading langchain_core-0.1.37-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.6/274.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.36-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.35-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.0/273.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.34-py3-none-any.whl (271 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain==0.1.5) (3.7.1)\n",
            "  Downloading langchain_core-0.1.32-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.31-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.29-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.6/252.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.27-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.26-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_core-0.1.25-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.24-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.3/241.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain==0.1.5)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.16->langchain==0.1.5)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.5) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.5) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.5) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.5) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.5) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.5) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.5) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.5) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain==0.1.5) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain==0.1.5) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.5)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.5 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87 marshmallow-3.21.1 mypy-extensions-1.0.0 packaging-23.2 typing-inspect-0.9.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.1.0\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.6.1\n",
            "Collecting unstructured==0.12.3\n",
            "  Downloading unstructured-0.12.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.3) (5.2.0)\n",
            "Collecting filetype (from unstructured==0.12.3)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured==0.12.3)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.3) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.3) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.3) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.3) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.3) (4.12.3)\n",
            "Collecting emoji (from unstructured==0.12.3)\n",
            "  Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.3) (0.6.4)\n",
            "Collecting python-iso639 (from unstructured==0.12.3)\n",
            "  Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured==0.12.3)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.3) (1.25.2)\n",
            "Collecting rapidfuzz (from unstructured==0.12.3)\n",
            "  Downloading rapidfuzz-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured==0.12.3)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.3) (4.10.0)\n",
            "Collecting unstructured-client>=0.15.1 (from unstructured==0.12.3)\n",
            "  Downloading unstructured_client-0.22.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.3) (1.14.1)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.3) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.3) (3.3.2)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client>=0.15.1->unstructured==0.12.3)\n",
            "  Downloading deepdiff-6.7.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=3.4 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.3) (3.6)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client>=0.15.1->unstructured==0.12.3)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: marshmallow>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.3) (3.21.1)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.3) (1.0.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.3) (23.2)\n",
            "Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.3) (4.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.3) (1.16.0)\n",
            "Requirement already satisfied: typing-inspect>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.3) (0.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.18 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.3) (2.0.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured==0.12.3) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.12.3) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.12.3) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.12.3) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.12.3) (4.66.2)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff>=6.0->unstructured-client>=0.15.1->unstructured==0.12.3)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=d752dd54b4ae3ace38f7b3a80b327e180869f479da562be51c9a0a803b2f5f5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, ordered-set, langdetect, jsonpath-python, emoji, backoff, deepdiff, unstructured-client, unstructured\n",
            "Successfully installed backoff-2.2.1 deepdiff-6.7.1 emoji-2.11.0 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 ordered-set-4.1.0 python-iso639-2024.2.7 python-magic-0.4.27 rapidfuzz-3.7.0 unstructured-0.12.3 unstructured-client-0.22.0\n",
            "Requirement already satisfied: unstructured[pdf]==0.12.3 in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (2.11.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (0.6.4)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (2024.2.7)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (1.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (1.25.2)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (3.7.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (4.10.0)\n",
            "Requirement already satisfied: unstructured-client>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (0.22.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (1.14.1)\n",
            "Collecting onnx (from unstructured[pdf]==0.12.3)\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2image (from unstructured[pdf]==0.12.3)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Collecting pdfminer.six (from unstructured[pdf]==0.12.3)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pikepdf (from unstructured[pdf]==0.12.3)\n",
            "  Downloading pikepdf-8.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.12.3) (4.1.0)\n",
            "Collecting unstructured-inference==0.7.23 (from unstructured[pdf]==0.12.3)\n",
            "  Downloading unstructured_inference-0.7.23-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured.pytesseract>=0.3.12 (from unstructured[pdf]==0.12.3)\n",
            "  Downloading unstructured.pytesseract-0.3.12-py3-none-any.whl (14 kB)\n",
            "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart (from unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (0.20.3)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (4.8.0.76)\n",
            "Collecting onnxruntime<1.16 (from unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (4.38.2)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (3.3.2)\n",
            "Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (6.7.1)\n",
            "Requirement already satisfied: idna>=3.4 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (3.6)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (1.0.6)\n",
            "Requirement already satisfied: marshmallow>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (3.21.1)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (1.0.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (1.16.0)\n",
            "Requirement already satisfied: typing-inspect>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (0.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.18 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (2.0.7)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]==0.12.3) (9.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured[pdf]==0.12.3) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]==0.12.3) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]==0.12.3) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]==0.12.3) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]==0.12.3) (4.66.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->unstructured[pdf]==0.12.3) (3.20.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[pdf]==0.12.3) (42.0.5)\n",
            "Collecting Pillow>=8.0.0 (from unstructured.pytesseract>=0.3.12->unstructured[pdf]==0.12.3)\n",
            "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from pikepdf->unstructured[pdf]==0.12.3)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]==0.12.3) (1.16.0)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client>=0.15.1->unstructured[pdf]==0.12.3) (4.1.0)\n",
            "Collecting coloredlogs (from onnxruntime<1.16->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.16->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.16->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (1.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (3.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (0.4.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (2023.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (1.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (1.5.3)\n",
            "Collecting iopath (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading pdfplumber-0.11.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (0.17.1+cu121)\n",
            "Collecting effdet (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytesseract (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]==0.12.3) (2.21)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<1.16->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm>=0.9.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (2.0.7)\n",
            "Collecting omegaconf>=2.0 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m464.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (12.4.99)\n",
            "Collecting portalocker (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (2023.4)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading pypdfium2-4.28.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<1.16->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (1.3.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured[pdf]==0.12.3) (3.1.2)\n",
            "Building wheels for collected packages: iopath, antlr4-python3-runtime\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=74f4494e49ceb5db95f3281a7a1c2fc56b216ca4ab7d3c326ea221f9d24397b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=e25c6ca8a72415cb82bccd6f9ea861da5d55e9cfec04d6f5587c3b3e6fd6e3cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built iopath antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, python-multipart, pypdfium2, portalocker, Pillow, onnx, omegaconf, humanfriendly, Deprecated, unstructured.pytesseract, pytesseract, pikepdf, pdf2image, iopath, coloredlogs, pdfminer.six, onnxruntime, pdfplumber, timm, layoutparser, effdet, unstructured-inference\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 Pillow-10.3.0 antlr4-python3-runtime-4.9.3 coloredlogs-15.0.1 effdet-0.4.1 humanfriendly-10.0 iopath-0.1.10 layoutparser-0.3.4 omegaconf-2.3.0 onnx-1.16.0 onnxruntime-1.15.1 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.0 pikepdf-8.14.0 portalocker-2.8.2 pypdfium2-4.28.0 pytesseract-0.3.10 python-multipart-0.0.9 timm-0.9.16 unstructured-inference-0.7.23 unstructured.pytesseract-0.3.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              },
              "id": "15a5074962514b04b0f37fbf5b620c72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Choose a dataset to use and then load it into your code\n",
        "Here we are using the pdfs loaded in pdfs/. We load this using langchain DirectoryLoader."
      ],
      "metadata": {
        "id": "5agp6iRm-7jD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can load multiple types of datasets into this example though the most commonly used are PDFs and websites.\n",
        "\n",
        "To load websites, we could also use `langchain WebBaseLoader`\n",
        "\n",
        "In this example, we will consider PDFs and load them in using `langchain DirectoryLoader`.\n",
        "\n",
        "We host all PDFs at the PDFs directory `llm-workshop/tutorials/04-rag/PDFs`\n",
        "\n"
      ],
      "metadata": {
        "id": "vBx0cQJ9Jmtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/argonne-lcf/llm-workshop.git"
      ],
      "metadata": {
        "id": "p8YpJK93pNsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc94927-1bd3-40a6-c691-519945885050"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llm-workshop'...\n",
            "remote: Enumerating objects: 273, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 273 (delta 64), reused 88 (delta 55), pack-reused 170\u001b[K\n",
            "Receiving objects: 100% (273/273), 44.89 MiB | 14.16 MiB/s, done.\n",
            "Resolving deltas: 100% (144/144), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "loader = DirectoryLoader('llm-workshop/tutorials/04-rag/PDFs', glob=\"**/*.pdf\", show_progress=True)\n",
        "papers = loader.load()"
      ],
      "metadata": {
        "id": "YYoEp4FJz6oK",
        "outputId": "3357c938-b135-4cf0-df43-f4c802c7d277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:25<00:00,  3.67s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Now, we need to split our documents into chunks.\n",
        "We want the embedding to be greater than 1 word but much less than an entire page. This is essential for the similarity search between the query and the document. Essentially, the query will be searched for greatest similarity to embedded chunks in the dataset. Then those chunks with greatest similarity are augmented to the query.\n",
        "\n",
        "It is essential to choose the chunking method according to your data type.\n",
        "There are different ways to do this:\n",
        "\n",
        "Fixed size\n",
        "*   Token: Splits text on tokens. Can chunk tokens together\n",
        "*   Character: Splits based on some user defined character.\n",
        "\n",
        "Recursive\n",
        "*  Recursively splits text. Useful for keeping related pieces of text next to each other.\n",
        "\n",
        "Document based\n",
        "*   HTML: Splits text based on HTML-specific characters.\n",
        "*   Markdown: Splits on Markdown-specific characters\n",
        "*   Code: Splits text based on characters specific to coding languages.\n",
        "\n",
        "Semantic chunking\n",
        "*   Extract semantic meaning from embeddings and then assess the semantic relationship between these chunks. Essentially splits into sentences, then groups into groups of 3 sentences, and then merges one that are similar in the embedding space.\n",
        "\n",
        "Here we use recursive where the dataset is split using a set of characters. The default characters provided to it are [\"\\n\\n\", \"\\n\", \" \", \"\"].  A large text is split by the first character \\n\\n. If the first split by \\n\\n is still large then it moves to the next character which is \\n and tries to split by it. This continues until the chunk size is reached.\n"
      ],
      "metadata": {
        "id": "wjvyEOMMBB7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "character_chunker = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separators=[\"\\n\\n\"])\n",
        "char_chunks = character_chunker.split_documents(papers)"
      ],
      "metadata": {
        "id": "SfgRcG6g0XOG"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in char_chunks[0:5]:\n",
        "  print(i, \"\\n\")"
      ],
      "metadata": {
        "id": "PBELhDegRTZ-",
        "outputId": "332b6bfb-8fe6-431d-ca81-8cad901009e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='0 2 0 2\\n\\nt c O 3 2\\n\\n]\\n\\nG L . s c [\\n\\n2 v 5 8 8 9 0 . 0 1 0 2 : v i X r a\\n\\nChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction\\n\\nSeyone Chithrananda University of Toronto seyone.chithrananda@utoronto.ca\\n\\nGabriel Grand Reverie Labs gabe@reverielabs.com\\n\\nBharath Ramsundar DeepChem bharath.ramsundar@gmail.com\\n\\nAbstract' metadata={'source': 'llm-workshop/tutorials/04-rag/PDFs/2010.09885.pdf'} \n",
            "\n",
            "page_content='\\n\\nGNNs and chemical ﬁngerprints are the predominant approaches to representing molecules for property prediction. However, in NLP, transformers have become the de-facto standard for representation learning thanks to their strong downstream task transfer. In parallel, the software ecosystem around transformers is maturing rapidly, with libraries like HuggingFace and BertViz enabling streamlined training and introspection. In this work, we make one of the ﬁrst attempts to systematically evaluate transformers on molecular property prediction tasks via our ChemBERTa model. While not at state-of-the-art, ChemBERTa scales well with pretraining dataset size, offering competitive downstream performance on MoleculeNet and useful attention-based visualization modalities. Our results suggest that transform- ers offer a promising avenue of future work for molecular representation learning and property prediction. To facilitate these efforts, we release a curated dataset of 77M SMILES from PubChem suitable for large-scale self-supervised pretraining.' metadata={'source': 'llm-workshop/tutorials/04-rag/PDFs/2010.09885.pdf'} \n",
            "\n",
            "page_content='1 Motivation\\n\\nMolecular property prediction has seen a recent resurgence thanks to the success of graph neural networks (GNNs) on various benchmark tasks [1, 2, 3, 4, 5, 6]. However, data scarcity remains a fundamental challenge for supervised learning in a domain in which each new labelled data point requires costly and time-consuming laboratory testing. Determining effective methods to make use of large amounts of unlabeled structure data remains an important unsolved challenge.' metadata={'source': 'llm-workshop/tutorials/04-rag/PDFs/2010.09885.pdf'} \n",
            "\n",
            "page_content='\\n\\nOver the past two years, the transformer [7, 8] has emerged as a robust architecture for learning self-supervised representations of text. Transformer pretraining plus task-speciﬁc ﬁnetuning provides substantial gains over previous approaches to many tasks in natural language processing (NLP) [9, 10, 11]. Meanwhile, software infrastructure for transformers is maturing rapidly: HuggingFace [12] provides streamlined pretraining and ﬁnetuning pipelines, while packages like BertViz [13] offer sophisticated interfaces for attention visualization. Given the availability of millions of SMILES strings, transformers offer an interesting alternative to both expert-crafted and GNN-learned ﬁnger- prints. In particular, the masked language-modeling (MLM) pretraining task [8] commonly used for BERT-style architectures is analogous to atom masking tasks used in graph settings [14]. Moreover, since modern transformers are engineered to scale to massive NLP corpora, they offer practical advantages over GNNs in terms of efﬁciency and throughput.' metadata={'source': 'llm-workshop/tutorials/04-rag/PDFs/2010.09885.pdf'} \n",
            "\n",
            "page_content='Though simple in concept, the application of transformers to molecular data presents several questions that are severely underexplored. For instance: How does pretraining dataset size affect downstream task performance? What tokenization strategies work best for SMILES? Does replacing SMILES\\n\\nPreprint. Submitted to 34th Conference on Neural Information Processing Systems (NeurIPS 2020).\\n\\nwith a more robust string representation like SELFIES [15] improve performance? We aim to address these questions via one of the ﬁrst systematic evaluations of transformers on molecular property prediction tasks.\\n\\n2 Related Work' metadata={'source': 'llm-workshop/tutorials/04-rag/PDFs/2010.09885.pdf'} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(papers)} papers have been split into {len(char_chunks)} chunks.\")"
      ],
      "metadata": {
        "id": "PcUt5rgsRo69",
        "outputId": "0e81f4d6-ce91-4eb9-8850-38f389d20e21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 papers have been split into 361 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparing Naive Chunking with Semantic Chunking"
      ],
      "metadata": {
        "id": "Ib00jI51bUIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "with open(\"state_of_the_union.txt\", \"r\") as f:\n",
        "  speech_text = f.read()\n",
        "\n",
        "speech =  Document(page_content=speech, metadata={\"source\": \"local\"})\n"
      ],
      "metadata": {
        "id": "Ve1TJoPGjY3q"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the encoder model.\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "model_name = \"sentence-transformers/msmarco-distilbert-dot-v5\"\n",
        "model_kwargs = {'device':'cuda'}\n",
        "encode_kwargs = {'normalize_embeddings':False}\n",
        "\n",
        "encoder = HuggingFaceEmbeddings(\n",
        "  model_name = model_name,\n",
        "  model_kwargs = model_kwargs,\n",
        "  encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "#Perform semantic chunking.\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "#initializing the splliter.\n",
        "semantic_chunker = SemanticChunker(encoder, buffer_size=5)\n",
        "\n",
        "#list of grouped_sentences (buffers)\n",
        "buffers = semantic_chunker.split_documents([speech])\n",
        "buffers = [buffer.page_content for buffer in buffers]\n",
        "semantic_chunks = semantic_chunker.create_documents(buffers)"
      ],
      "metadata": {
        "id": "ogYJBUDxbegf"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "character_chunker = CharacterTextSplitter(chunk_size=500, chunk_overlap=150, separator=\" \")\n",
        "char_chunks = character_chunker.split_documents([speech])"
      ],
      "metadata": {
        "id": "lcr_mLCVkX2a"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(semantic_chunks)\n",
        "random.shuffle(char_chunks)\n",
        "\n",
        "print(\"Semantic chunking\")\n",
        "for i in semantic_chunks[0:10]:\n",
        "  print(i, \"\\n\")\n",
        "\n",
        "print(\"\\n\\n ----------- \\n\\n\")\n",
        "\n",
        "print(\"Fixed-size character chunking\")\n",
        "for i in char_chunks[0:10]:\n",
        "  print(i, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbC1xF_Mc5Ma",
        "outputId": "dc728f36-5a06-4dfe-89e6-e188c0ea0c43"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic chunking\n",
            "page_content=\"Throughout our history, no issue has united this country more than our security. Sadly, some of the unity we felt after 9/11 has dissipated. We can argue all we want about who's to blame for this, but I am not interested in relitigating the past. I know that all of us love this country.\" \n",
            "\n",
            "page_content=\"These nations aren't standing still. These nations aren't playing for second place. They're putting more emphasis on math and science. They're rebuilding their infrastructure. They are making serious investments in clean energy because they want those jobs.\" \n",
            "\n",
            "page_content=\"And we cannot do it again. Rather than fight the same tired battles that have dominated Washington for decades, it's time to try something new. Let's invest in our people without leaving them a mountain of debt. Let's meet our responsibility to the citizens who sent us here. Let's try common sense. To do that, we have to recognize that we face more than a deficit of dollars right now. We face a deficit of trust -- deep and corrosive doubts about how Washington works that have been growing for years. To close that credibility gap we must take action on both ends of Pennsylvania Avenue to end the outsized influence of lobbyists; to do our work openly and to give our people the government they deserve. That's what I came to Washington to do. That's why -- for the first time in history -- my administration posts our White House visitors online. And that's why we've excluded lobbyists from policymaking jobs or seats on federal boards and commissions. But we can't stop there. It's time to require lobbyists to disclose each contact they make on behalf of a client with my administration or Congress.\" \n",
            "\n",
            "page_content=\"That is why jobs must be our number one focus in 2010, and that is why I am calling for a new jobs bill tonight. Now, the true engine of job creation in this country will always be America's businesses. But government can create the conditions necessary for businesses to expand and hire more workers. We should start where most new jobs do -- in small businesses, companies that begin when an entrepreneur takes a chance on a dream or a worker decides it's time she became her own boss. Through sheer grit and determination, these companies have weathered the recession and are ready to grow. But when you talk to small business owners in places like Allentown, Pa., or Elyria, Ohio, you find out that even though banks on Wall Street are lending again, they are mostly lending to bigger companies. But financing remains difficult for small business owners across the country. So tonight, I'm proposing that we take $30 billion of the money Wall Street banks have repaid and use it to help community banks give small businesses the credit they need to stay afloat. I am also proposing a new small business tax credit -- one that will go to over 1 million small businesses who hire new workers or raise wages. While we're at it, let's also eliminate all capital gains taxes on small business investment and provide a tax incentive for all businesses, large and small, to invest in new plants and equipment. Next, we can put Americans to work today building the infrastructure of tomorrow.\" \n",
            "\n",
            "page_content=\"For example, some members of Congress post some earmark requests online. Tonight, I'm calling on Congress to publish all earmark requests on a single Web site before there's a vote, so that the American people can see how their money is being spent. Of course, none of these reforms will even happen if we don't also reform how we work with one another. Now, I am not naive. I never thought the mere fact of my election would usher in peace, harmony and some post-partisan era. I knew that both parties have fed divisions that are deeply entrenched. And on some issues, there are simply philosophical differences that will always cause us to part ways.\" \n",
            "\n",
            "page_content=\"We cut taxes for 8 million Americans paying for college. As a result, millions of Americans had more to spend on gas, and food and other necessities, all of which helped businesses keep more workers. And we haven't raised income taxes by a single dime on a single person. Not a single dime. Because of the steps we took, there are about 2 million Americans working right now who would otherwise be unemployed -- 200,000 work in construction and clean energy, 300,000 are teachers and other education workers, tens of thousands are cops, firefighters, correctional officers and first responders. And we are on track to add another one-and-a-half-million jobs to this total by the end of the year. The plan that has made all of this possible, from the tax cuts to the jobs, is the Recovery Act. That's right -- the Recovery Act, also known as the stimulus bill. Economists on the left and the right say that this bill has helped saved jobs and avert disaster. But you don't have to take their word for it. Talk to the small business in Phoenix that will triple its work force because of the Recovery Act. Talk to the window manufacturer in Philadelphia who said he used to be skeptical about the Recovery Act, until he had to add two more work shifts just because of the business it created. Talk to the single teacher raising two kids who was told by her principal in the last week of school that because of the Recovery Act, she wouldn't be laid off after all. There are stories like this all across America. And after two years of recession, the economy is growing again. Retirement funds have started to gain back some of their value. Businesses are beginning to invest again, and slowly some are starting to hire again. But I realize that for every success story, there are other stories, of men and women who wake up with the anguish of not knowing where their next paycheck will come from -- who send out resumes week after week and hear nothing in response.\" \n",
            "\n",
            "page_content=\"These aren't Republican values or Democratic values they're living by, business values or labor values. They are American values. Unfortunately, too many of our citizens have lost faith that our biggest institutions -- our corporations, our media and, yes, our government -- still reflect these same values. Each of these institutions are full of honorable men and women doing important work that helps our country prosper. But each time a CEO rewards himself for failure, or a banker puts the rest of us at risk for his own selfish gain, people's doubts grow. Each time lobbyists game the system or politicians tear each other down instead of lifting this country up, we lose faith. The more that TV pundits reduce serious debates into silly arguments and big issues into sound bites, our citizens turn away. No wonder there's so much cynicism out there. No wonder there's so much disappointment. I campaigned on the promise of change -- change we can believe in, the slogan went. And right now, I know there are many Americans who aren't sure if they still believe we can change -- or at least, that I can deliver it. But remember this -- I never suggested that change would be easy or that I can do it alone.\" \n",
            "\n",
            "page_content=\"To help working families, we will extend our middle-class tax cuts. But at a time of record deficits, we will not continue tax cuts for oil companies, investment fund managers and those making over $250,000 a year. We just can't afford it. Now, even after paying for what we spent on my watch, we will still face the massive deficit we had when I took office. More importantly, the cost of Medicare, Medicaid and Social Security will continue to skyrocket. That's why I've called for a bipartisan fiscal commission, modeled on a proposal by Republican Judd Gregg and Democrat Kent Conrad. This can't be one of those Washington gimmicks that lets us pretend we solved a problem. The commission will have to provide a specific set of solutions by a certain deadline. Yesterday, the Senate blocked a bill that would have created this commission. So I will issue an executive order that will allow us to go forward, because I refuse to pass this problem on to another generation of Americans. And when the vote comes tomorrow, the Senate should restore the pay-as-you-go law that was a big reason why we had record surpluses in the 1990s. I know that some in my own party will argue that we cannot address the deficit or freeze government spending when so many are still hurting. I agree, which is why this freeze will not take effect until next year, when the economy is stronger. But understand -- if we do not take meaningful steps to rein in our debt, it could damage our markets, increase the cost of borrowing and jeopardize our recovery -- all of which could have an even worse effect on our job growth and family incomes. From some on the right, I expect we'll hear a different argument -- that if we just make fewer investments in our people, extend tax cuts for wealthier Americans, eliminate more regulations and maintain the status quo on health care, our deficits will go away. The problem is, that's what we did for eight years.\" \n",
            "\n",
            "page_content='The spirit that has sustained this nation for more than two centuries lives on in you, its people. We have finished a difficult year.' \n",
            "\n",
            "page_content='And God Bless the United States of America. ' \n",
            "\n",
            "\n",
            "\n",
            " ----------- \n",
            "\n",
            "\n",
            "Fixed-size character chunking\n",
            "page_content=\"Germany's not waiting; India's not waiting. These nations aren't standing still. These nations aren't playing for second place. They're putting more emphasis on math and science. They're rebuilding their infrastructure. They are making serious investments in clean energy because they want those jobs.\\n\\nWell I do not accept second place for the United States of America. As hard as it may be, as uncomfortable and contentious as the debates may be, it's time to get serious about fixing the problems\" metadata={'source': 'local'} \n",
            "\n",
            "page_content=\"To help working families, we will extend our middle-class tax cuts. But at a time of record deficits, we will not continue tax cuts for oil companies, investment fund managers and those making over $250,000 a year. We just can't afford it.\\n\\nNow, even after paying for what we spent on my watch, we will still face the massive deficit we had when I took office. More importantly, the cost of Medicare, Medicaid and Social Security will continue to skyrocket. That's why I've called for a bipartisan\" metadata={'source': 'local'} \n",
            "\n",
            "page_content=\"middle class families. That's why we're nearly doubling the child care tax credit, and making it easier to save for retirement by giving every worker access to a retirement account and expanding the tax credit for those who start a nest egg. That's why we're working to lift the value of a family's single largest investment -- their home. The steps we took last year to shore up the housing market have allowed millions of Americans to take out new loans and save an average of $1,500 on mortgage\" metadata={'source': 'local'} \n",
            "\n",
            "page_content=\"to work today building the infrastructure of tomorrow. From the first railroads to the interstate highway system, our nation has always been built to compete. There's no reason Europe or China should have the fastest trains or the new factories that manufacture clean energy products.\\n\\nTomorrow, I'll visit Tampa, Fla., where workers will soon break ground on a new high-speed railroad funded by the Recovery Act. There are projects like that all across this country that will create jobs and help\" metadata={'source': 'local'} \n",
            "\n",
            "page_content=\"reform. Not now. Not when we are so close. Let us find a way to come together and finish the job for the American people.\\n\\nNow, even as health care reform would reduce our deficit, it's not enough to dig us out of a massive fiscal hole in which we find ourselves. It's a challenge that makes all others that much harder to solve, and one that's been subject to a lot of political posturing.\\n\\nSo let me start the discussion of government spending by setting the record straight. At the beginning of\" metadata={'source': 'local'} \n",
            "\n",
            "page_content=\"area is more ripe for such innovation than energy. You can see the results of last year's investment in clean energy -- in the North Carolina company that will create 1,200 jobs nationwide helping to make advanced batteries, or in the California business that will put 1,000 people to work making solar panels.\\n\\nBut to create more of these clean energy jobs, we need more production, more efficiency, more incentives. That means building a new generation of safe, clean nuclear power plants in this\" metadata={'source': 'local'} \n",
            "\n",
            "page_content='Most of this was the result of not paying for two wars, two tax cuts and an expensive prescription drug program. On top of that, the effects of the recession put a $3 trillion hole in our budget. That was before I walked in the door.\\n\\nNow if we had taken office in ordinary times, I would have liked nothing more than to start bringing down the deficit. But we took office amid a crisis, and our efforts to prevent a second depression have added another $1 trillion to our national debt.\\n\\nI am' metadata={'source': 'local'} \n",
            "\n",
            "page_content='And what keeps me going -- what keeps me fighting -- is that despite all these setbacks, that spirit of determination and optimism -- that fundamental decency that has always been at the core of the American people -- lives on. It lives on in the struggling small business owner who wrote to me of his company, \"None of us,\" he said, \"are willing to consider, even slightly, that we might fail.\"\\n\\nIt lives on in the woman who said that even though she and her neighbors have felt the pain of' metadata={'source': 'local'} \n",
            "\n",
            "page_content='largest increase in investments for veterans in decades. That is why we are building a 21st century VA. And that is why Michelle has joined with Jill Biden to forge a national commitment to support military families.\\n\\nEven as we prosecute two wars, we are also confronting perhaps the greatest danger to the American people -- the threat of nuclear weapons. I have embraced the vision of John F. Kennedy and Ronald Reagan through a strategy that reverses the spread of these weapons and seeks a world' metadata={'source': 'local'} \n",
            "\n",
            "page_content=\"deep and corrosive doubts about how Washington works that have been growing for years. To close that credibility gap we must take action on both ends of Pennsylvania Avenue to end the outsized influence of lobbyists; to do our work openly and to give our people the government they deserve.\\n\\nThat's what I came to Washington to do. That's why -- for the first time in history -- my administration posts our White House visitors online. And that's why we've excluded lobbyists from policymaking jobs\" metadata={'source': 'local'} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of chunks produced by semantic chunking: {len(semantic_chunks)}\")\n",
        "print(f\"Number of chunks produced by character chunking: {len(char_chunks)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06M-jDjBmsQO",
        "outputId": "aae208c7-ccdf-403d-fd58-924ac9a3ee4d"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks produced by semantic chunking: 48\n",
            "Number of chunks produced by character chunking: 117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ProTip: Semantic Chunking is not suitable to poorly-parsed PDF contents."
      ],
      "metadata": {
        "id": "InCjG0vln9Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the biomedical domain-specific encoder model.\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "model_name = \"pritamdeka/S-PubMedBert-MS-MARCO\"\n",
        "model_kwargs = {'device':'cuda'}\n",
        "encode_kwargs = {'normalize_embeddings':False}\n",
        "\n",
        "biomedical_encoder = HuggingFaceEmbeddings(\n",
        "  model_name = model_name,\n",
        "  model_kwargs = model_kwargs,\n",
        "  encode_kwargs=encode_kwargs\n",
        ")\n"
      ],
      "metadata": {
        "id": "yOrKjSCtoMbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform semantic chunking on scientific papers.\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "#initializing the splliter.\n",
        "semantic_chunker = SemanticChunker(biomedical_encoder, buffer_size=5)\n",
        "\n",
        "#list of grouped_sentences (buffers)\n",
        "buffers = semantic_chunker.split_documents(papers)\n",
        "buffers = [buffer.page_content for buffer in buffers]\n",
        "semantic_chunks = semantic_chunker.create_documents(buffers)\n",
        "\n",
        "for i in semantic_chunks[0:10]:\n",
        "  print(i, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOCrOZ1nrGBN",
        "outputId": "409a064a-2e65-4506-91e2-985055d7892c"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='0 2 0 2\\n\\nt c O 3 2\\n\\n]\\n\\nG L . s c [\\n\\n2 v 5 8 8 9 0 . 0 1 0 2 : v i X r a\\n\\nChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction\\n\\nSeyone Chithrananda University of Toronto seyone.chithrananda@utoronto.ca\\n\\nGabriel Grand Reverie Labs gabe@reverielabs.com\\n\\nBharath Ramsundar DeepChem bharath.ramsundar@gmail.com\\n\\nAbstract\\n\\nGNNs and chemical ﬁngerprints are the predominant approaches to representing molecules for property prediction. However, in NLP, transformers have become the de-facto standard for representation learning thanks to their strong downstream task transfer. In parallel, the software ecosystem around transformers is maturing rapidly, with libraries like HuggingFace and BertViz enabling streamlined training and introspection. In this work, we make one of the ﬁrst attempts to systematically evaluate transformers on molecular property prediction tasks via our ChemBERTa model. While not at state-of-the-art, ChemBERTa scales well with pretraining dataset size, offering competitive downstream performance on MoleculeNet and useful attention-based visualization modalities. Our results suggest that transform- ers offer a promising avenue of future work for molecular representation learning and property prediction.' \n",
            "\n",
            "page_content='To facilitate these efforts, we release a curated dataset of 77M SMILES from PubChem suitable for large-scale self-supervised pretraining. 1 Motivation\\n\\nMolecular property prediction has seen a recent resurgence thanks to the success of graph neural networks (GNNs) on various benchmark tasks [1, 2, 3, 4, 5, 6]. However, data scarcity remains a fundamental challenge for supervised learning in a domain in which each new labelled data point requires costly and time-consuming laboratory testing. Determining effective methods to make use of large amounts of unlabeled structure data remains an important unsolved challenge. Over the past two years, the transformer [7, 8] has emerged as a robust architecture for learning self-supervised representations of text. Transformer pretraining plus task-speciﬁc ﬁnetuning provides substantial gains over previous approaches to many tasks in natural language processing (NLP) [9, 10, 11]. Meanwhile, software infrastructure for transformers is maturing rapidly: HuggingFace [12] provides streamlined pretraining and ﬁnetuning pipelines, while packages like BertViz [13] offer sophisticated interfaces for attention visualization. Given the availability of millions of SMILES strings, transformers offer an interesting alternative to both expert-crafted and GNN-learned ﬁnger- prints. In particular, the masked language-modeling (MLM) pretraining task [8] commonly used for BERT-style architectures is analogous to atom masking tasks used in graph settings [14]. Moreover, since modern transformers are engineered to scale to massive NLP corpora, they offer practical advantages over GNNs in terms of efﬁciency and throughput. Though simple in concept, the application of transformers to molecular data presents several questions that are severely underexplored. For instance: How does pretraining dataset size affect downstream task performance? What tokenization strategies work best for SMILES? Does replacing SMILES\\n\\nPreprint.' \n",
            "\n",
            "page_content='Submitted to 34th Conference on Neural Information Processing Systems (NeurIPS 2020). with a more robust string representation like SELFIES [15] improve performance? We aim to address these questions via one of the ﬁrst systematic evaluations of transformers on molecular property prediction tasks. 2 Related Work\\n\\nIn cheminformatics, there is a long tradition of training language models directly on SMILES to learn continuous latent representations [16, 17, 18]. Typically, these are RNN sequence-to-sequence models and their goal is to facilitate auxiliary lead optimization tasks; e.g., focused library generation [19]. Thus far, discussion of the transformer architecture in chemistry has been largely focused on a particular application to reaction prediction [20]. Some recent work has pretrained transformers for molecular property prediction and reported promis- ing results [21, 22]. However, the datasets used for pretraining have been relatively small (861K compounds from ChEMBL and 2M compounds from ZINC, respectively). Other work has used larger pretraining datasets (18.7M compounds from ZINC) [23] but the effects of pretraining dataset size, tokenizer, and string representation were not explored. In still other work, transformers were used for supervised learning directly without pretraining [24]. Recently, a systematic study of self-supervised pretraining strategies for GNNs helped to clarify the landscape of those methods [14]. Our goal is to undertake a similar investigation for transformers to assess the viability of this architecture for property prediction. 3 Methods\\n\\nChemBERTa is based on the RoBERTa [25] transformer implementation in HuggingFace [12]. Our implementation of RoBERTa uses 12 attention heads and 6 layers, resulting in 72 distinct attention mechanisms. So far, we have released 15 pre-trained ChemBERTa models on the Huggingface’s model hub; these models have collectively received over 30,000 Inference API calls to date.1\\n\\nWe used the popular Chemprop library for all baselines [6]. We trained the directed Message Passing Neural Network (D-MPNN) with default hyperparameters as well as the sklearn-based [26] Random Forest (RF) and Support Vector Machine (SVM) models from Chemprop, which use 2048-bit Morgan ﬁngerprints from RDKit [27, 28]. 3.1 PreTraining on PubChem 77M\\n\\nWe adopted our pretraining procedure from RoBERTa, which masks 15% of the tokens in each input string. We used a max. vocab size of 52K tokens and max. sequence length of 512 tokens.' \n",
            "\n",
            "page_content='We trained for 10 epochs on all PubChem subsets except for the 10M subset, on which we trained for 3 epochs to avoid observed overﬁtting.' \n",
            "\n",
            "page_content='Our hypothesis is that, in learning to recover masked tokens, the model forms a representational topology of chemical space that should generalize to property prediction tasks. For pretraining, we curated a dataset of 77M unique SMILES from PubChem [29], the world’s largest open-source collection of chemical structures. The SMILES were canonicalized and globally shufﬂed to facilitate large-scale pretraining. We divided this dataset into subsets of 100K, 250K, 1M, and 10M. Pretraining on the largest subset took approx. 48 hours on a single NVIDIA V100 GPU. We make this dataset publicly available and leave pretraining on the full 77M set to future work. 3.2 Finetuning on MoleculeNet\\n\\nWe evaluated our models on several classiﬁcation tasks from MoleculeNet [30] selected to cover a range of dataset sizes (1.5K - 41.1K examples) and medicinal chemistry applications (brain penetrability, toxicity, and on-target inhibition). These included the BBBP, ClinTox, HIV, and Tox21 datasets. For datasets with multiple tasks, we selected a single representative task: the clinical toxicity (CT_TOX) task from ClinTox and the p53 stress-response pathway activation (SR-p53) task from\\n\\n1The main model directory can be viewed here. Each model includes the speciﬁc tokenizer (BPE, SMILES-\\n\\ntokenized), representation (SMILES, SELFIES) and number of training steps (’150k’) appended in its name. 2\\n\\nBBBP 2,039\\n\\nClinTox (CT_TOX) 1,478\\n\\nHIV 41,127\\n\\nTox21 (SR-p53) 7,831\\n\\nROC\\n\\nPRC\\n\\nROC\\n\\nPRC\\n\\nROC\\n\\nPRC\\n\\nROC\\n\\nPRC\\n\\nChemBERTa 10M 0.643 0.708 D-MPNN 0.681 RF 0.702 SVM\\n\\n0.620 0.697 0.692 0.724\\n\\n0.733 0.906 0.693 0.833\\n\\n0.975 0.993 0.968 0.986\\n\\n0.622 0.752 0.780 0.763\\n\\n0.119 0.152 0.383 0.364\\n\\n0.728 0.688 0.724 0.708\\n\\n0.207 0.429 0.335 0.345\\n\\nTable 1: Comparison of ChemBERTa pretrained on 10M PubChem compounds and Chemprop baselines on selected MoleculeNet tasks. We report both ROC-AUC and PRC-AUC to give a full picture of performance on class-imbalanced tasks.' \n",
            "\n",
            "page_content='Tox21. For each dataset, we generated an 80/10/10 train/valid/test split using the scaffold splitter from DeepChem [31].' \n",
            "\n",
            "page_content='During ﬁnetuning, we appended a linear classiﬁcation layer and backpropagated through the base model. We ﬁnetuned models for up to 25 epochs with early stopping on ROC- AUC. We release a tutorial in DeepChem which allows users to go through loading a pre-trained ChemBERTa model, running masked prediction tasks, visualizing the attention of the model on several molecules, and ﬁne-tuning the model on the Tox21 SR-p53 dataset. 4 Results\\n\\nOn the MoleculeNet tasks that we evaluated, ChemBERTa approaches, but does not beat, the strong baselines from Chemprop (Table 1).2 Nevertheless, downstream performance of ChemBERTa scales well with more pretraining data (Fig. 1). On average, scaling from 100K to 10M resulted in ∆ROC-AUC = +0.110 and ∆PRC-AUC = +0.059. (HIV was omitted from this analysis due to resource constraints.) These results suggest that ChemBERTa learns more robust representations with additional data and is able to leverage this information when learning downstream tasks. Figure 1: Scaling the pretraining size (100K, 250K, 1M, 10M) produces consistent improvements in downstream task performance on BBBP, ClinTox, and Tox21. Mean ∆AUC across all three tasks with a 68% conﬁdence interval is shown in light blue. 2While Tox21 ROC-AUC is better than the baselines, PR-AUC is considerably lower. 3\\n\\n(a)\\n\\n(b)\\n\\n(c)\\n\\nFigure 2: (a) Attention in GNNs highlights a problematic ketone in a Tox21 compound. (b) Attention over SMILES tokens in ChemBERTa provides a close analogue to graph attention. (c) Neural stack trace enables ﬁne-grained introspection of neuron behavior. (b - c) produced via BertViz [13]. 4.1 Tokenizers\\n\\nOur default tokenization strategy uses a Byte-Pair Encoder (BPE) from the HuggingFace tokenizers library [12]. BPE is a hybrid between character and word-level representations, which allows for the handling of large vocabularies in natural language corpora. Motivated by the intuition that rare and unknown words can often be decomposed into multiple known subwords, BPE ﬁnds the best word segmentation by iteratively and greedily merging frequent pairs of characters [32]. We compare this tokenization algorithm with a custom SmilesTokenizer based on a regex from [20], which we have released as part of DeepChem [31].3\\n\\nTo compare tokenizers, we pretrained two identical models on the PubChem-1M set. The pretrained models were evaluated on the Tox21 SR-p53 task. We found that the SmilesTokenizer narrowly outperformed BPE by ∆PRC-AUC = +0.015. Though this result suggests that a more semantically- relevant tokenization may provide performance beneﬁts, further benchmarking on additional datasets is needed to validate this ﬁnding. 4.2 SMILES vs. SELFIES\\n\\nIn addition to SMILES, we pretrained ChemBERTA on SELFIES (SELF-referencing Embedded Strings) [15]. SELFIES is an alternate molecular string representation designed for machine learning. Because every valid SELFIES corresponds to a valid molecule, we hypothesized that SELFIES would lead to a more robust model. However, we found no signiﬁcant difference in downstream performance on the Tox21 SR-p53 task. Further benchmarking is needed to validate this ﬁnding. 4.3 Attention Visualization\\n\\nWe used BertViz [13] to inspect the attention heads of ChemBERTa (SmilesTokenizer version) on Tox21, and contrast them to the molecular graph visualization of an attention-based GNN. We found certain neurons that were selective for chemically-relevant functional groups, and aromatic rings. We also observed other neurons that tracked bracket closures – a ﬁnding in keeping with results on attention-based RNNs showing the ability to track nested parentheses [33, 34]. 5 Discussion\\n\\nIn this work, we introduce ChemBERTa, a transformer architecture for molecular property prediction. Initial results show that MLM pretraining provides a boost in predictive power for models on selected downstream tasks from MoleculeNet. However, with the possible exception of Tox21, ChemBERTa still performs below state-of-the-art on these tasks. Our current analysis covers only a small portion of the hypothesis space we hope to explore. We plan to expand our evaluations to all of MoleculeNet, undertake more systematic hyperparameter\\n\\n3https://deepchem.readthedocs.io/en/latest/tokenizers.html#smilestokenizer\\n\\n4\\n\\ntuning, experiment with larger masking rates, and explore multitask ﬁnetuning. In parallel, we aim to scale up pretraining, ﬁrst to the full PubChem 77M dataset, then to even larger sets like ZINC-15 (with 270 million compounds). This work will require us to improve our engineering infrastructure considerably. As we scale up, we are also actively investigating methods to improve sample efﬁciency. Alternative text-based pretraining methods like ELECTRA may be useful [10]. Separately, there is little question that graph representations provide useful inductive biases for learning molecular structures. Recent hybrid graph transformer models [22, 35] may provide better sample efﬁciency while retaining the scalability of attention-based architectures. Broader Impact\\n\\nA core goal of AI for drug discovery is to accelerate the development of new and potentially life-saving medicines. Research to improve the accuracy and generalizability of molecular property prediction methods contributes directly to these aims. Nevertheless, machine learning—and particularly large- scale pretraining of the form we undertake here—is a resource-intensive process that has a growing carbon footprint [36]. According to the Machine Learning Emissions Calculator (https://mlco2. github.io/impact), we estimate that our pretraining generated roughly 17.1 kg CO2eq (carbon- dioxide equivalent) of emissions. Fortunately, Google Cloud Platform, which we used for this work, is certiﬁed carbon-neutral and offsets 100% of emissions (https://cloud.google.com/ sustainability).' \n",
            "\n",
            "page_content='Even as we advocate for further exploration of large-scale pretraining for property prediction, we also encourage other researchers to be mindful of the environmental impact of these efforts and opt for sustainable cloud compute solutions where possible. Acknowledgments and Disclosure of Funding\\n\\nWe would like to thank the Tyler Cowen and the Emergent Ventures fellowship for providing the research grant to S.C. for cloud computing and various research expenses, alongside the Thiel Foundation for funding the grant. Thanks to Mario Krenn, Alston Lo, Akshat Nigam, Professor Alan Aspuru-Guzik and the entire Aspuru-Guzik group for early discussions and mentorship regarding the potiential for applying large-scale transformers on molecular strings, as well as in motivating the utilization of SELFIES in this work.' \n",
            "\n",
            "page_content='We would also like to thank the entire DeepChem team for their support and early discussions on fostering the ChemBERTa concept, and helping with designing and hosting the Tokenizers API and ChemBERTa tutorial. Thanks to the Reverie team for authorizing our usage of the PubChem 77M dataset, which was processed, ﬁltered and split by them. References\\n\\n[1] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alán Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular ﬁngerprints. In Advances in neural information processing systems, pages 2224– 2232, 2015.' \n",
            "\n",
            "page_content='[2] Steven Kearnes, Kevin McCloskey, Marc Berndl, Vijay Pande, and Patrick Riley. Molecular graph convolutions: moving beyond ﬁngerprints.' \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Then we embed the chunked texts using a Transformer and create a Faiss Vector Database\n",
        "This allows us to encode the text into our search. Let's investigate the retrieved documents for a query.\n",
        "\n",
        "Vector databases, also called vector storage, efficiently store and retrieve vector data, which are arrays of numerical values representing points in multi-dimensional space. They're useful for handling data like embeddings from deep learning models or numerical features. Unlike traditional relational databases, which aren't optimized for vectors, vector databases offer efficient storage, indexing, and querying for high-dimensional and variable-length vectors.\n",
        "\n",
        "There are various types of vector databases:\n",
        "1. Chroma\n",
        "2. FAISS\n",
        "3. Pinecone\n",
        "4. Weaviate\n",
        "5. Qdrant\n",
        "\n",
        "Here, we build this using the FAISS utility."
      ],
      "metadata": {
        "id": "YyTRRvU6DboO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "faiss_vector_db = FAISS.from_documents(semantic_chunks, biomedical_encoder)\n",
        "question = \"Do you have any information on publications about RFDiffusion?\"\n",
        "searchDocs = faiss_vector_db.similarity_search(question)\n",
        "\n",
        "#investigate top-3 nearest (most relevant) documents for the query.\n",
        "print(searchDocs[0].page_content)\n",
        "print(searchDocs[1].page_content)\n",
        "print(searchDocs[2].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fRCusd9royy",
        "outputId": "e80573b1-d3a5-42bd-ad9e-19aca5aba0d2"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "experimentally characterized designs. J.W., A.L. and W.S. contributed additional code. S.O. implemented RFdiffusion on Google Colab.\n",
            "9h). Over the binder alone, the experimental structure deviates from the RFdiffusion design by only 0.6 Å (Fig. 6h). These results demonstrate the ability of RFdiffusion to generate new proteins with atomic level accuracy, and to precisely target functionally relevant sites on therapeutically important proteins. Discussion RFdiffusion is a comprehensive improvement over current protein design methods. RFdiffusion readily generates diverse uncondi- tional designs up to 600 residues in length that are accurately pre- dicted by AF2, far exceeding the complexity and accuracy achieved by most previous methods (a recent Hallucination-based approach also achieved high unconditional performance53). Half of our tested unconditional designs express in a soluble way, and have circular dichroism spectra consistent with the design models and high ther- mostability. Despite their substantially increased complexity, the ideality and stability of RFdiffusion designs is akin to that of de novo protein designs generated using previous methods such as Rosetta. RFdiffusion enables generation of higher-order architectures with any desired symmetry, unlike Hallucination methods, which have so far been limited to cyclic symmetries. Electron microscopy confirmed that the structures of these oligomers are very similar to the design mod- els, which in many cases show little global similarity to known protein oligomers. There has been recent progress in scaffolding protein functional motifs using deep-learning methods (RF Hallucination, RFjoint Inpainting and diffusion), but Hallucination is slow for large systems, Inpainting fails when insufficient starting information is provided and previous diffusion methods had low accuracy. RFdiffusion outperforms these previous methods in the complexity of the motifs that can be scaf- folded, the precision with which sidechains are positioned (for cataly- sis and other functions), and the accuracy of motif recapitulation by AF2. The design of MDM2 binding proteins with three orders of magni- tude higher affinities than the scaffolded P53 motif demonstrates the robustness of RFdiffusion motif scaffolding. Combining accurate motif scaffolding with the design of symmetric assemblies enabled consist- ent and atomically precise positioning of sidechains to coordinate Ni2+ ions across diverse tetrameric assemblies\n",
            "\n",
            "For binder design from target structural information alone, previous work required testing tens of thousands of sequences12. RFdiffusion, when combined with improved filtering26 raises experimental success rates by two orders of magnitude; high-affinity binders can be identi- fied from dozens of designs, in many cases eliminating the require- ment for slow and expensive high-throughput screening (at least for the non-polar sites targeted here; further studies will be required to assess success rates on more polar target sites and sites without native binding partners). A high-resolution cryo-EM structure of one of these designs in complex with influenza HA shows that RFdiffusion can design functional proteins with atomic accuracy. Vázquez Torres et al. demonstrate the ability of RFdiffusion to design picomolar affin- ity binders to flexible helical peptides54, further highlighting its use for de novo binder design. Vázquez Torres et al. also show how RFdiffusion\n",
            "\n",
            "can be extended for protein model refinement by partial noising and denoising, which enables tuneable sampling around a given input structure. For peptide binder design, this enabled increases in affin- ity of nearly three orders of magnitude without high-throughput screening. The breadth and complexity of problems solvable with RFdiffusion and the robustness and accuracy of the solutions far exceeds what has been achieved previously. In a manner reminiscent of the generation of images from text prompts, RFdiffusion makes possible, with mini- mal specialist knowledge, the generation of functional proteins from minimal molecular specifications (for example, high-affinity binders to a user-specified target protein, and diverse protein assemblies from user-specified symmetries). The power and scope of RFdiffusion can be extended in several directions. RF has recently been extended to nucleic acids and protein–nucleic acid complexes55, which should enable RFdiffusion to design nucleic acid binding proteins and perhaps folded RNA struc- tures. Extension of RF to incorporate ligands should similarly enable extension of RFdiffusion to explicitly model ligand atoms, and allow the design of protein–ligand interactions. The ability to customize RFdif- fusion to specific design challenges by addition of external potentials and by fine-tuning (as illustrated here for catalytic site scaffolding, binder-targeting and fold specification), along with continued improve- ments to the underlying methodology, should enable de novo protein design to achieve still higher levels of complexity, to approach and, in some cases, surpass what natural evolution has achieved. Online content Any methods, additional references, Nature Portfolio reporting summa- ries, source data, extended data, supplementary information, acknowl- edgements, peer review information; details of author contributions and competing interests; and statements of data and code availability are available at https://doi.org/10.1038/s41586-023-06415-8. 1. 2. Dauparas, J.\n",
            "One hundred designs were generated per problem, with no previous optimization on the benchmark set (some optimization was necessary for Hallucination). Supplementary Table 10 presents full results. In silico success rates on the problems are correlated between the methods, and RFdiffusion can still struggle on challenging problems in which all methods have low success. b, Four examples of designs in which RFdiffusion significantly outperforms existing methods. Teal, native motif; colours, AF2 prediction of a design. Metrics (r.m.s.d. AF2 versus design/versus native motif (Å), AF2 pAE): 5TRV long, 1.17/0.57; 4.73; 6E6R long, 0.89/0.27, 4.56; 7MRX long, 0.84/0.82 4.32; 5TPN, 0.59/0.49 3.77. c, RFdiffusion can scaffold the p53 helix that binds MDM2\n",
            "\n",
            "(left) and makes extra contacts with the target (right, average 31% increased surface area. Design was p53_design_89). Designs were generated with an RFdiffusion model fine-tuned on complexes. d, BLI measurements indicate high-affinity binding to MDM2 (p53_design_89, 0.7 nM; p53_design_53, 0.5 nM); the native affinity is 600 nM (ref. 42). e, Out of 95 designs, 55 showed binding to MDM2 (more than 50% of maximum response). Thirty-two of these were monomeric (Supplementary Fig. 10h). f, After fine-tuning (Supplementary Methods), RFdiffusion can scaffold enzyme active sites. An oxidoreductase example (EC1) is shown (PDB 1A4I); catalytic site (teal); RFdiffusion output (grey, model; colours, AF2 prediction); zoom of active site. AF2 versus design backbone r.m.s.d. 0.88 Å, AF2 versus design motif backbone r.m.s.d. 0.53 Å, AF2 versus design motif full-atom r.m.s.d. 1.05 Å, AF2 pAE 4.47. g, In silico success rates on active sites derived from EC1-5 (AF2 Motif r.m.s.d.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![vector_database](https://github.com/argonne-lcf/llm-workshop/blob/main/tutorials/04-rag/rag_images/vector_database.png?raw=1)\n",
        "\n",
        "Image credit: https://blog.gopenai.com/primer-on-vector-databases-and-retrieval-augmented-generation-rag-using-langchain-pinecone-37a27fb10546"
      ],
      "metadata": {
        "id": "NqccXGwoEYP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Initialize the LLM that will be used for question answering"
      ],
      "metadata": {
        "id": "5A56JddAEkCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we use a pretrained model flan-t5-large as part of a HuggingFacePipeline. This will later be chained with the vector database for RAG."
      ],
      "metadata": {
        "id": "tdUokERIMnz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM,pipeline\n",
        "from langchain import HuggingFacePipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n",
        "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
        "llm = HuggingFacePipeline(\n",
        "   pipeline = pipe,\n",
        "   model_kwargs={\"temperature\": 0, \"max_length\": 2048, \"max_new_tokens\": 1024, \"device\":\"cuda\"},\n",
        ")\n"
      ],
      "metadata": {
        "id": "9CXf3N6c134r"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Retrieve data and use it to answer a question"
      ],
      "metadata": {
        "id": "EvJhhDzYEvhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![rag_workflow](https://github.com/argonne-lcf/llm-workshop/blob/main/tutorials/04-rag/rag_images/rag_workflow.png?raw=1)\n",
        "\n",
        "Image credit: https://blog.gopenai.com/retrieval-augmented-generation-101-de05e5dc21ef"
      ],
      "metadata": {
        "id": "QOQG22pHOf5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's ask questions it would only be able to know if the model actually read the texts!"
      ],
      "metadata": {
        "id": "jWJHxBc9hzJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"You are an honest and helpful AI. You are alwasys truthful and concise in your answers. Please answer the question with the provided context.\n",
        "If you don't know the answer, please say I don't know.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "nMrN1_3B2cA1"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "  llm=llm,\n",
        "  chain_type=\"stuff\",\n",
        "  retriever=faiss_vector_db.as_retriever(),\n",
        "  chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")\n",
        "result = qa_chain ({ \"query\" : \"What technique proposed in 2023 can be used to predict protein folding?\" })\n",
        "print(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLCz3eiX2e0g",
        "outputId": "e029791d-db56-4b12-89fe-b889754e0dbe"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2041 > 512). Running this sequence through the model will result in indexing errors\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RoseTTAFold diffusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's ask the chain where to find the article related to RFDiffusion"
      ],
      "metadata": {
        "id": "ynkOkS39K2FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain ({ \"query\" : \"Where was the RFdiffusion paper published?\" })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKAT3UJU2DGo",
        "outputId": "972059bb-75c5-4772-e180-c81e441a4d76"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Where was the RFdiffusion paper published?', 'result': 'Nature'}"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain ({ \"query\" : \"What can I use RFdiffusion model for?\" })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfO4a1s7ycai",
        "outputId": "0072248b-f7b9-4e5b-ea4d-2820f32af33f"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What can I use RFdiffusion model for?', 'result': \"I don't know\"}"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sUSceP382mYA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}