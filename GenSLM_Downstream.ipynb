{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Background\n",
        "\n",
        "## DNA Melting Point\n",
        "\n",
        "__Wikipedia:__\n",
        "\n",
        "Nucleic acid thermodynamics is the study of how temperature affects the nucleic acid structure of double-stranded DNA (dsDNA). The melting temperature (Tm) is defined as the temperature at which half of the DNA strands are in the random coil or single-stranded (ssDNA) state. Tm depends on the length of the DNA molecule and its specific nucleotide sequence. DNA, when in a state where its two strands are dissociated (i.e., the dsDNA molecule exists as two independent strands), is referred to as having been denatured by the high temperature.\n",
        "\n",
        "\n",
        "## This notebook\n",
        "\n",
        "In this notebook we will use the GenSLM 25M parameter langauge model to generate embeddings for sequences and use a downstream model to take the embeddings and predict the melting point of the associated sequence. This workflow is common for many bioinformatics tasks, and can easily be adapted to other regression and classification problems."
      ],
      "metadata": {
        "id": "jFJQeb_qraNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing GenSLM\n",
        "# NOTE: You may need to run this twice due env reload\n",
        "!pip install git+https://github.com/ramanathanlab/genslm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsDHUoNGU62n",
        "outputId": "c5357654-6a32-4478-8867-21163c320131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ramanathanlab/genslm\n",
            "  Cloning https://github.com/ramanathanlab/genslm to /tmp/pip-req-build-ix5b5ho0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ramanathanlab/genslm /tmp/pip-req-build-ix5b5ho0\n",
            "  Resolved https://github.com/ramanathanlab/genslm to commit e4fbf3b8e641150d708c18e12d551de8ed0cae1c\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers@ git+https://github.com/maxzvyagin/transformers (from genslm==0.0.4a1)\n",
            "  Cloning https://github.com/maxzvyagin/transformers to /tmp/pip-install-llnybjky/transformers_6c0a0afb79344dea9bf91c9be61e3141\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/maxzvyagin/transformers /tmp/pip-install-llnybjky/transformers_6c0a0afb79344dea9bf91c9be61e3141\n",
            "  Resolved https://github.com/maxzvyagin/transformers to commit ffd5aba0ad41a1ebd1897a77f6a3782fc2d75e1f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytorch-lightning==1.6.5 in /usr/local/lib/python3.10/dist-packages (from genslm==0.0.4a1) (1.6.5)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from genslm==0.0.4a1) (0.16.5)\n",
            "Requirement already satisfied: pydantic==1.10.2 in /usr/local/lib/python3.10/dist-packages (from genslm==0.0.4a1) (1.10.2)\n",
            "Requirement already satisfied: biopython==1.79 in /usr/local/lib/python3.10/dist-packages (from genslm==0.0.4a1) (1.79)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from genslm==0.0.4a1) (1.5.3)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from genslm==0.0.4a1) (8.4.0)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from genslm==0.0.4a1) (3.1.3)\n",
            "Requirement already satisfied: h5py==3.7.0 in /usr/local/lib/python3.10/dist-packages (from genslm==0.0.4a1) (3.7.0)\n",
            "Requirement already satisfied: lightning-transformers==0.2.1 in /usr/local/lib/python3.10/dist-packages (from genslm==0.0.4a1) (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython==1.79->genslm==0.0.4a1) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (4.66.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (1.3.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (2.18.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (0.2.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (9.4.0)\n",
            "Requirement already satisfied: protobuf==3.20.1 in /usr/local/lib/python3.10/dist-packages (from lightning-transformers==0.2.1->genslm==0.0.4a1) (3.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.2->genslm==0.0.4a1) (4.10.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.5->genslm==0.0.4a1) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.5->genslm==0.0.4a1) (2023.6.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.5->genslm==0.0.4a1) (2.15.2)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.5->genslm==0.0.4a1) (0.3.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.5->genslm==0.0.4a1) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (0.20.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (0.12.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->genslm==0.0.4a1) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->genslm==0.0.4a1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->genslm==0.0.4a1) (2023.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->genslm==0.0.4a1) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->genslm==0.0.4a1) (3.1.42)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->genslm==0.0.4a1) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->genslm==0.0.4a1) (1.44.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->genslm==0.0.4a1) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->genslm==0.0.4a1) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->genslm==0.0.4a1) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->genslm==0.0.4a1) (1.4.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->genslm==0.0.4a1) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (3.9.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb->genslm==0.0.4a1) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers@ git+https://github.com/maxzvyagin/transformers->genslm==0.0.4a1) (2024.2.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (3.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (12.4.99)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (0.11.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->lightning-transformers==0.2.1->genslm==0.0.4a1) (0.70.16)\n",
            "Requirement already satisfied: mecab-ko>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.0.1)\n",
            "Requirement already satisfied: mecab-python3>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.0.8)\n",
            "Requirement already satisfied: mecab-ko-dic>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.0.0)\n",
            "Requirement already satisfied: ipadic>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.0.0)\n",
            "Requirement already satisfied: nltk>=3.6 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (3.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (4.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->genslm==0.0.4a1) (5.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6->torchmetrics>=0.7.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.3.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->lightning-transformers==0.2.1->genslm==0.0.4a1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.6.5->genslm==0.0.4a1) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn import svm\n",
        "from google.colab import drive\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from genslm import GenSLM, SequenceDataset"
      ],
      "metadata": {
        "id": "2Y9RyjnkdsUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aquiring Model and Data\n",
        "\n",
        "Visit: https://drive.google.com/drive/folders/1oYgda4Px-tugapgE2uumiUIf2p3PqIQI?usp=drive_link\n",
        "\n",
        "- Right click `UmichSciFM-2024` Folder and click Organize -> Add Shortcut -> All Locations -> My Drive\n",
        "\n",
        "Executing the cell below mounts your Google Drive to this notebook giving you access to the model checkpoint and data for this notebook"
      ],
      "metadata": {
        "id": "WNXGN5fTV65k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount and see file structure\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "!ls drive/MyDrive/UMichSciFM-2024/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17wF__wFLl9_",
        "outputId": "8cce57bd-aa2d-459a-ca8b-f140a1ef880a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "data  model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and view the dataset, split into train/test\n",
        "data = pd.read_csv(\"drive/MyDrive/UMichSciFM-2024/data/meltingpoint.csv\", index_col=0)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8gGfdw6Ya3SN",
        "outputId": "8a8c278e-63d5-4e11-885e-dc77d7f9ad70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Sequence  MeltingPoint\n",
              "0     atgattatttccgcagccagcgattatcgcgccgcagcacaacgca...     82.112491\n",
              "1     atggctaagctgaccaagcgcatgcgcgtgatccgtgacaaagttg...     80.338892\n",
              "2     atgtttaaaaataaaatgatgatttgtctttatatgtttctattat...     76.102904\n",
              "3     atgggtcgactggaaggaaaggtagcgatcgtcacgggcggtgcgc...     86.743695\n",
              "4     atgcgtctaaaccccggccaacaacaagctgtcgaattcgttaccg...     81.709235\n",
              "...                                                 ...           ...\n",
              "9411  gtggatatgagtaatacaagtgcagcaccacgtgacacgtgggggt...     78.878742\n",
              "9412  ttggttgagcgccacgacatcgcaaccggtgccaccgggcgtaacc...     82.666703\n",
              "9413  atgttccgttcgcttcttcgcctgtctgcagcgttgctggccttga...     85.151774\n",
              "9414  gtgaaattactagatttattgtcaaaaggaattgtaataggtgatg...     75.071559\n",
              "9415  gtggaaatgtcacaactttcaccacgccgtccgtatctgctgcgcg...     81.473411\n",
              "\n",
              "[9416 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-655c858f-3490-4151-910f-ed3f7b7468d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sequence</th>\n",
              "      <th>MeltingPoint</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>atgattatttccgcagccagcgattatcgcgccgcagcacaacgca...</td>\n",
              "      <td>82.112491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atggctaagctgaccaagcgcatgcgcgtgatccgtgacaaagttg...</td>\n",
              "      <td>80.338892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>atgtttaaaaataaaatgatgatttgtctttatatgtttctattat...</td>\n",
              "      <td>76.102904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>atgggtcgactggaaggaaaggtagcgatcgtcacgggcggtgcgc...</td>\n",
              "      <td>86.743695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>atgcgtctaaaccccggccaacaacaagctgtcgaattcgttaccg...</td>\n",
              "      <td>81.709235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9411</th>\n",
              "      <td>gtggatatgagtaatacaagtgcagcaccacgtgacacgtgggggt...</td>\n",
              "      <td>78.878742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9412</th>\n",
              "      <td>ttggttgagcgccacgacatcgcaaccggtgccaccgggcgtaacc...</td>\n",
              "      <td>82.666703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9413</th>\n",
              "      <td>atgttccgttcgcttcttcgcctgtctgcagcgttgctggccttga...</td>\n",
              "      <td>85.151774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9414</th>\n",
              "      <td>gtgaaattactagatttattgtcaaaaggaattgtaataggtgatg...</td>\n",
              "      <td>75.071559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9415</th>\n",
              "      <td>gtggaaatgtcacaactttcaccacgccgtccgtatctgctgcgcg...</td>\n",
              "      <td>81.473411</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9416 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-655c858f-3490-4151-910f-ed3f7b7468d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-655c858f-3490-4151-910f-ed3f7b7468d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-655c858f-3490-4151-910f-ed3f7b7468d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c3a542ab-4c45-43aa-892b-594b6b03ff10\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3a542ab-4c45-43aa-892b-594b6b03ff10')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c3a542ab-4c45-43aa-892b-594b6b03ff10 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 9416,\n  \"fields\": [\n    {\n      \"column\": \"Sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9416,\n        \"samples\": [\n          \"atgcagtcaataacacctccattaattgccgttattggtagcgatggttcaggcaagtcaacggtgtgtgaacatcttattaccgttgtcgaaaaatatggtgctgccgaaagagttcatttaggaaaacaggccggaaatgtcggtcgtgcagtgacaaaattaccgttgatgggaaaatccttacataaaacaattgaacgaaatcaggtgaaaacagcaaaaaaattgccaggaccagttccggcgctggtaattacagcgtttgtcgcccgtcgcttactgcgctttcgtcatatgcttgcctgtcgtcgtcgcgggttaattgttctaaccgaccgttatcctcaggaccaaattcctggcgcttacgatggtacggtgttcccacctaacgttgaaggtggtcgttttgtctcatggctggcaagccaggaacgtaaagcgtttcactggatggcgagccataagcctgatctggtcatcaaactcaatgttgaccttgaagttgcctgcgcgcgtaaacccgaccataaacgggaatcgctggcgaggaagattgccataacgccacagttaacctttggtggtgcacnnnnnnnnnngcctgaccacaaaagggagtcgctggcaagaaagatagccataacgccacagttaacctttggtggtgcacaactggttgatatcgatgccaatcagccactggaacaggtgctgattgatgcagaaaaagcgattacggattttatgaccgcgcgtggttatcactag\",\n          \"atgaacgaaatggatcgcgcggggcaggccgcgcgggatgcgggctacggcccggagcacgacgccgaagcgcagtcgaaccatgaggccgaacgcgagcgccgccgccgtctcaacgaagaacttatcgacgcctacgacgaagagctcgaaatggaagtcgacgatcgcctgcaggaaggcggtctggaaatcagcgaagaagcgcgcgcgctgcgcaaggtctatttccgcgagctgatccgcctgcagggcgaactggtgaagatgcaggactggatcatgagcacgggccaccggctcgtggtgatcttcgaagggcgcgatgcggcgggcaagggcggcgtgatcaagcgcatcacgcagcgcctgaacccgcgcatgtgccgcgtggctgcgctgcccgcgccgaacaaccgcgaacgcacgcagtggtatttccagcgctacgttcagcatctgccggcgggcggcgaaatggtgctgttcgaccgcagttggtacaaccgcgcgggcgtcgagcgcgtgatgaacttctgcacggacgacgagtacgaggagtttttccgctcggtgcccgagttcgaaaagatgctggtgcgcagcggcatccagatcgtcaagtactggttttcgatcaccgacgacgagcaggaagtgcgcttccagagccgtatcgacgatccgctcaagcagtggaagctctcgccgatggatctcgaaagccgtcgccgctgggaagcctatacgcaagtcaaggaagcgatgctgcagcgctcgcatattccggaagcgccgtggtgggtggtgcagggcgtggacaagaagcgcgcgcgcctgaactgcatccatcatctgctcagccaggtgccttatcacgaggtcgagcatccggcggtgacgctgcccgcgcgcgtgcatcatccggactatattcgccagccggtgccccctgagatgttcgtgcccgagctgtactga\",\n          \"atgagtgatgtcgccgagacactagatcctttgcgcttgcccttacagggcgagcgcctgattgaagcctctgccggcacaggcaaaacctttacgattgcggcgctttatttgcgcctgttacttggactaggcggttccgccgcctttccccgcccgctgaccgttgaagaactgctggtggtcacctttaccgaggctgccacggcagaattgcgcggtcgtatccgtagcaatatccacgagttgcgcatcgcctgtctgcgtgaaaccaccgacaatccattgtacgaacacctgctggaagaggtcgacgataaagcgcaagccgcgcagtggttgttgttagccgaacggcagatggatgaagcggcagtctttactattcacggcttttgccagcgcatgctcaacctgaatgcctttgaatccggcatgctgtttgagcagcagctgattgaagatgagtctctgctacgctaccaggcctgcgccgatttctggcgtcgccactgctacccgctgccgcgtgaaatagcccaggtcgtctttgaaacctggaaagggccgcaggcgttgctgcgcgatattaatcgttatctgcaaggcgaagcgccggttatcaaagcaccgccgcccgatgatgaaacgctagcttcccgtcacgcgcaaattgtggcgcgtattgatacggtaaaacagcagtggcgcgacgcagtgggtgaactggatgcgctgatcgaatcttctggtattgatcgacgcaagtttaaccgtagcaatcaggctaaatggatcgacaagatcagcgcctgggcagaagaagagacaaacagttatcagttgccggagtcgctggaaaaattctcccagcgtttcttagaagatcgcacgaaagccgggggggaaaccccgcgacatccactgtttgaggcgatcgatcaactgcttgcagaaccattgtcgatccgtgatctggtgatcacccgcgcattggctgagatccgcgaaacagtagcgcgtgaaaaacgccgccgtggcgaattgggttttgatgacatgttaagtcggctcgattccgcgctgcgtagcgaaagcggcgaggtgttggcagcggcgatccgtacgcgattcccggtggcaatgatcgatgaatttcaggataccgacccccagcagtaccgaatttttcgccgtatctggcaccatcagccagaaaccgcattgttgctgattggcgacccgaagcaggccatatatgcattccggggtgcggatatcttcacttatatgaaggcgcgtagtgaagttcacgcccactacactttagacaccaactggcgctccgcacctggaatggtgaacagtgtgaacaagcttttcagccagactgatgacgcgttcatgtttcgcgaaataccgtttattccagtgaaatcagccgggaaaaatcaggcgttacgttttgtctttaaaggtgaaacgcagcctgcgatgaaaatgtggctgatggaaggcgaaagctgcggcgttggcgactatcaaagtaccatggcgcaggtatgtgctgcgcaaatccgcgactggctacaagccggacagcggggcgaagcgttgctgatgaacggcgacgacgcgcgtccggtgcgtgcttcggacatcagcgtgctggtgcgcagccgccaggaggccgcccaggtgcgcgatgccttaacgttgctggaaatcccttccgtttacctttcgaaccgcgatagtgtttttgaaactctggaagcgcaggaaatgctttggctgttgcaggcggtgatgacgcccgaacgtgagaacaccctgcgcagtgcgctggcaacgtcaatgatggggctgaatgcgctggatattgaaacgctgaataatgacgaacatgcgtgggatgcggtagtcgaagagttcgatggttatcggcaaatctggcgcaaacgtggcgttatgccgatgctgcgggcgctgatgtcggcgcgtaacattgcagaaaacttgctggcaacggcaggcggtgagcggcgtcttaccgatatcttgcatatcagcgaactgcttcaagaagccggaacgcagctggaaagtgaacatgcgctggtacgctggttatcgcaacatatcctcgagccagacagtaatgcctccagccaacaaatgcgcctcgaaagtgataaacatctggtgcagattgtcacgatccataaatcgaaagggctggaatatccgctggtctggttgccatttattaccaatttccgcgtccaggatcaggcgttttatcacgatcgccactcgtttgaggcagttttggatcttaatgctgcgccagaaagcgtcgacctcgcggaggtcgaacgtctggcggaagatctgcgtttgctttacgtggcgctgacgcgttcggtttggcattgcagtctcggcgttgcaccgctggtgcgccgtcgtggcgataaaaaaggtgacaccgacgtccaccaaagtgcgctcgggcgtttgctgcaaaaaggggaaccgcaagatgcggcagggcttcgcacctgtattgaagcgttatgcgatgatgatattgcctggcaaacggcacaaactggtgataaccagccctggcaggttaatgatgctttaactgcagaactgaatgcgaggacactacaacgattgcccggcgataactggcgtgtcaccagctactccggcttgcagcagcgtggtcacggtatcgctcaggatctgatgccacggctggatgttgatgccgcaggcgtggtcagcgtcgttgaagaaccgacgttaacaccgcatcagttcccgcgcggtgcgtcaccggggacattcttgcacagtttgtttgaagacctcgattttacccagccggttgacccgaactgggtacaggaaaaactggaactcggcggctttgaatcgcagtgggaaccggtgttgaccgagtggatcacggctgtcctccaggcacctctcaatgaaacgggtgttagcctgagtcagctttccgaccgcgataaacaggtggagatggagttttacctgccgattagcgaaccgctcatcgccagccagcttgatgcactaattcgccagtttgacccgctatccgctggctgcccgccgctggagttcatgcaggtacgcggcatgttaaaaggctttatcgacctggtattccgccacgaagggcgttattacctgctcgactataaatccaactggctgggtgaagacagttcggcttacacccaacaggctatggcagcagcgatgcaggcacaccgctatgatctgcaatatcagctttataccctggcgctgcatcgctatctgcgccatcgcattgctgattacgactatgatcgtcactttggcggcgttatctatctgttcctgcgtggcgttgataaagaacatccgcaacaagggatttacacaacccgacccaacgccgggttgattgccctgannnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnngcgacctgtgtcagtga\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MeltingPoint\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.410651190284151,\n        \"min\": 59.988225598748514,\n        \"max\": 92.8046865040983,\n        \"num_unique_values\": 9144,\n        \"samples\": [\n          90.42050760245908,\n          85.22620636797927,\n          80.8018901950218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset for use later\n",
        "\n",
        "# Returns two independent dataframes that we will use for\n",
        "# melting point modelling\n",
        "train, test = train_test_split(data, train_size=1000, test_size=200)"
      ],
      "metadata": {
        "id": "qNHyufydcKy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Begin Modelling\n",
        "\n",
        "Below is an example of generating embeddings with GenSLM-25M, we will follow this generat workflow to generate embeddings for our dataset, and use a downstream model to predict the melting point of an input sequence"
      ],
      "metadata": {
        "id": "dGfPlMChXypQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load model\n",
        "model = GenSLM(\"genslm_25M_patric\", model_cache_dir=\"drive/MyDrive/UMichSciFM-2024/model\")\n",
        "model.eval()\n",
        "\n",
        "# Select GPU device if it is available, else use CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# Input data is a list of gene sequences\n",
        "sequences = [\n",
        "    \"ATGAAAGTAACCGTTGTTGGAGCAGGTGCAGTTGGTGCAAGTTGCGCAGAATATATTGCA\",\n",
        "    \"ATTAAAGATTTCGCATCTGAAGTTGTTTTGTTAGACATTAAAGAAGGTTATGCCGAAGGT\",\n",
        "]\n",
        "\n",
        "example_dataset = SequenceDataset(sequences, model.seq_length, model.tokenizer)\n",
        "example_dataloader = DataLoader(example_dataset, batch_size =2)\n",
        "\n",
        "# Compute averaged-embeddings for each input sequence\n",
        "embeddings = []\n",
        "with torch.no_grad():\n",
        "    for batch in example_dataloader:\n",
        "        outputs = model(\n",
        "            batch[\"input_ids\"].to(device),\n",
        "            batch[\"attention_mask\"].to(device),\n",
        "            output_hidden_states=True,\n",
        "        )\n",
        "        # outputs.hidden_states shape: (layers, batch_size, sequence_length, hidden_size)\n",
        "        # Use the embeddings of the last layer\n",
        "        emb = outputs.hidden_states[-1].detach().cpu().numpy()\n",
        "        # Compute average over sequence length\n",
        "        emb = np.mean(emb, axis=1)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "# Concatenate embeddings into an array of shape (num_sequences, hidden_size)\n",
        "embeddings = np.concatenate(embeddings)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH_WlPYNXhq2",
        "outputId": "9681bc2a-7a3e-4dec-820d-5a1c129dce2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing...: 100%|██████████| 2/2 [00:00<00:00, 204.53it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get embeddings for training dataset\n",
        "train_dataset = SequenceDataset(train.Sequence.values, model.seq_length, model.tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8)\n",
        "\n",
        "# Compute averaged-embeddings for each input sequence\n",
        "train_embeddings = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(train_dataloader, desc=\"Embedding\"):\n",
        "        outputs = model(\n",
        "            batch[\"input_ids\"].to(device),\n",
        "            batch[\"attention_mask\"].to(device),\n",
        "            output_hidden_states=True,\n",
        "        )\n",
        "        # outputs.hidden_states shape: (layers, batch_size, sequence_length, hidden_size)\n",
        "        # Use the embeddings of the last layer\n",
        "        emb = outputs.hidden_states[-1].detach().cpu().numpy()\n",
        "        # Compute average over sequence length\n",
        "        emb = np.mean(emb, axis=1)\n",
        "        train_embeddings.append(emb)\n",
        "\n",
        "# Concatenate embeddings into an array of shape (num_sequences, hidden_size)\n",
        "train_embeddings = np.concatenate(train_embeddings)\n",
        "train_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG66v3y6YzHj",
        "outputId": "8c94f9bb-7896-4fec-8271-22c4df5f33cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing...: 100%|██████████| 1000/1000 [00:08<00:00, 123.48it/s]\n",
            "Embedding: 100%|██████████| 125/125 [01:38<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SVM on embeddings for melting point\n",
        "mp_regr = svm.SVR()\n",
        "mp_regr.fit(train_embeddings, train.MeltingPoint.values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "T99uwyOOcxXF",
        "outputId": "ea8b1343-8836-44fc-b51e-de902715f45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "oB-6ezWfha_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get embeddings for evaluation dataset\n",
        "test_dataset = SequenceDataset(test.Sequence.values, model.seq_length, model.tokenizer)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8)\n",
        "\n",
        "# Compute averaged-embeddings for each input sequence\n",
        "test_embeddings = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader, desc=\"Embedding\"):\n",
        "        outputs = model(\n",
        "            batch[\"input_ids\"].to(device),\n",
        "            batch[\"attention_mask\"].to(device),\n",
        "            output_hidden_states=True,\n",
        "        )\n",
        "        # outputs.hidden_states shape: (layers, batch_size, sequence_length, hidden_size)\n",
        "        # Use the embeddings of the last layer\n",
        "        emb = outputs.hidden_states[-1].detach().cpu().numpy()\n",
        "        # Compute average over sequence length\n",
        "        emb = np.mean(emb, axis=1)\n",
        "        test_embeddings.append(emb)\n",
        "\n",
        "# Concatenate embeddings into an array of shape (num_sequences, hidden_size)\n",
        "test_embeddings = np.concatenate(test_embeddings)\n",
        "test_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRGswn1OhNMj",
        "outputId": "cc757195-f5d2-42a6-84be-c0acc970ea13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing...: 100%|██████████| 200/200 [00:00<00:00, 508.65it/s]\n",
            "Embedding: 100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the regressor on a held out test set\n",
        "\n",
        "r2 = mp_regr.score(test_embeddings, test.MeltingPoint.values)\n",
        "\n",
        "print(f\"Regressor R^2 {r2} for test set\")\n",
        "\n",
        "# Test a few examples and see predictions\n",
        "example_predictions = mp_regr.predict(test_embeddings[:10])\n",
        "\n",
        "for (idx, row), pred_val in zip(test.iterrows(), example_predictions):\n",
        "  print(f\"Empirical melting point: {row['MeltingPoint']:.3f}\\t\\tPredicted melting point: {pred_val:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPCYHM5dhi7N",
        "outputId": "d0d7adb8-5bf3-4547-fab8-33582b786a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regressor R^2 0.9679511430339508 for test set\n",
            "Empirical melting point: 76.496\t\tPredicted melting point: 74.922\n",
            "Empirical melting point: 84.790\t\tPredicted melting point: 84.878\n",
            "Empirical melting point: 81.261\t\tPredicted melting point: 81.668\n",
            "Empirical melting point: 74.420\t\tPredicted melting point: 75.971\n",
            "Empirical melting point: 81.411\t\tPredicted melting point: 81.480\n",
            "Empirical melting point: 80.978\t\tPredicted melting point: 81.500\n",
            "Empirical melting point: 88.151\t\tPredicted melting point: 88.375\n",
            "Empirical melting point: 80.331\t\tPredicted melting point: 79.350\n",
            "Empirical melting point: 85.033\t\tPredicted melting point: 84.702\n",
            "Empirical melting point: 82.632\t\tPredicted melting point: 82.331\n"
          ]
        }
      ]
    }
  ]
}